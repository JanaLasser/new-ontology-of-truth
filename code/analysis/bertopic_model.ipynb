{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: fabio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and wrangle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>party</th>\n",
       "      <th>avg_belief_score</th>\n",
       "      <th>avg_truth_score</th>\n",
       "      <th>classes_quant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1469053054121136130</td>\n",
       "      <td>20597460</td>\n",
       "      <td>today Mexico join a grow number of nation as t...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>0.564275</td>\n",
       "      <td>0.536386</td>\n",
       "      <td>dn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1468826484668305411</td>\n",
       "      <td>20597460</td>\n",
       "      <td># IXPE be up and away ! I can not wait to see ...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>0.645782</td>\n",
       "      <td>0.590827</td>\n",
       "      <td>dn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1468326655789776906</td>\n",
       "      <td>20597460</td>\n",
       "      <td>.@NASA mourn the loss of a beloved member of o...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>0.497919</td>\n",
       "      <td>0.395466</td>\n",
       "      <td>dn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  author_id  \\\n",
       "0  1469053054121136130   20597460   \n",
       "1  1468826484668305411   20597460   \n",
       "2  1468326655789776906   20597460   \n",
       "\n",
       "                                          lemmatized     party  \\\n",
       "0  today Mexico join a grow number of nation as t...  Democrat   \n",
       "1  # IXPE be up and away ! I can not wait to see ...  Democrat   \n",
       "2  .@NASA mourn the loss of a beloved member of o...  Democrat   \n",
       "\n",
       "   avg_belief_score  avg_truth_score classes_quant  \n",
       "0          0.564275         0.536386            dn  \n",
       "1          0.645782         0.590827            dn  \n",
       "2          0.497919         0.395466            dn  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_lemma.csv.gzip\"\n",
    "tweets = pd.read_csv(\n",
    "    Path(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    dtype={\"id\":str}\n",
    ")\n",
    "tweets = tweets.dropna(subset=[\"lemmatized\"])\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase `n_neigbors` and/or `min_topic_size` if too many topics:\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=150, \n",
    "    n_components=5, \n",
    "    metric=\"cosine\", \n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "vectorizer_model = CountVectorizer(min_df=50)\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    verbose=True,\n",
    "    nr_topics=\"auto\",\n",
    "    min_topic_size=200,\n",
    "    umap_model=umap_model,\n",
    "    top_n_words=10,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    language=\"english\"\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(tweets.lemmatized.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"BERTopic_model\"\n",
    "topic_model.save(Path(dst, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export topic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table with docs and respective topics\n",
    "df_all_docs = pd.DataFrame({\n",
    "    #\"id\": tweets[\"id\"], \n",
    "    \"party\": tweets[\"party\"], \n",
    "    'topic': topics\n",
    "})\n",
    "\n",
    "# save for plotting belief-speaking similarity and truth-seeking\n",
    "# similarity in supplementary figure 5\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"topics_all_docs.csv.gzip\"\n",
    "df_all_docs.to_csv(\n",
    "    Path(dst, fname),\n",
    "    compression=\"gzip\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "topics_per_class = topic_model.topics_per_class(\n",
    "    docs=docs, \n",
    "    topics=topics, \n",
    "    classes=tweets[\"classes_quant\"], \n",
    "    global_tuning=True\n",
    ")\n",
    "fname = \"topics_per_class_ddr.csv\"\n",
    "topics_per_class.to_csv(Path(dst, fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many topics the model found\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"topics_info.csv\"\n",
    "topic_info = pd.DataFrame(topic_model.get_topic_info())\n",
    "topic_info.to_csv(Path(dst, fname), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "fname = \"BERTopic_model\"\n",
    "topic_model = BERTopic.load(Path(src, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the topics (call `x.write_html(path)` to save the graphs)\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap(n_clusters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Topic Modelling (topics over time):\n",
    "topics, probs = topic_model.transform(docs)\n",
    "timestamps = data.created_at.to_list()\n",
    "topics_over_time = topic_model.topics_over_time(docs, topics, timestamps, nr_bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics_per_class(topics_per_class, top_n_topics=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data to create the scattertext plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_ids = []  # insert topic id(s)\n",
    "topics_words = []\n",
    "topic_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in topics_ids:\n",
    "    word_list = []\n",
    "    embedding_list = []\n",
    "    for i in range(\n",
    "        0, 20\n",
    "    ):  # insert how many words you want to display (=< top_n_words in model computation)\n",
    "        word = topic_model.get_topic(id)[i][0]\n",
    "        word_list.append(word)\n",
    "        embedding = topic_model.get_topic(id)[i][1]\n",
    "        embedding_list.append(embedding)\n",
    "    topics_words.append(word_list)\n",
    "    topic_embeddings.append(embedding_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_df = pd.DataFrame()\n",
    "wordcloud_df[\"topic_ids\"] = topics_ids\n",
    "wordcloud_df[\"topic_words\"] = topics_words\n",
    "wordcloud_df[\"topic_embeddings\"] = topic_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = \"../../data/tweets\"\n",
    "fname = \"key_topics.csv\"\n",
    "wordcloud_df = wordcloud_df.set_index([\"topic_ids\"]).apply(pd.Series.explode).reset_index()\n",
    "wordcloud_df.to_csv(Path(dst, fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "260abd549318bbbd6a07931d7c19284ef86ae3047ff26637378d5cbd84eee02c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
