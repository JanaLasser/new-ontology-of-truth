{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: fabio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and wrangle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>party</th>\n",
       "      <th>avg_belief_score</th>\n",
       "      <th>avg_truth_score</th>\n",
       "      <th>classes_quant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1608863852950880256</td>\n",
       "      <td>211530910</td>\n",
       "      <td>two of my provision be include in the # ndaa ....</td>\n",
       "      <td>Republican</td>\n",
       "      <td>0.261409</td>\n",
       "      <td>0.327746</td>\n",
       "      <td>rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1608516681701244929</td>\n",
       "      <td>211530910</td>\n",
       "      <td># 2022RECAP : do we want the world fuel by Ame...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>0.709661</td>\n",
       "      <td>0.649962</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1608499794997116928</td>\n",
       "      <td>211530910</td>\n",
       "      <td>I vote for legislation that will spur innovati...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>0.683822</td>\n",
       "      <td>0.672940</td>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  author_id  \\\n",
       "0  1608863852950880256  211530910   \n",
       "1  1608516681701244929  211530910   \n",
       "2  1608499794997116928  211530910   \n",
       "\n",
       "                                          lemmatized       party  \\\n",
       "0  two of my provision be include in the # ndaa ....  Republican   \n",
       "1  # 2022RECAP : do we want the world fuel by Ame...  Republican   \n",
       "2  I vote for legislation that will spur innovati...  Republican   \n",
       "\n",
       "   avg_belief_score  avg_truth_score classes_quant  \n",
       "0          0.261409         0.327746            rn  \n",
       "1          0.709661         0.649962            rb  \n",
       "2          0.683822         0.672940            rt  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_lemma.csv.gzip\"\n",
    "tweets = pd.read_csv(\n",
    "    Path(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    dtype={\"id\":str}\n",
    ")\n",
    "tweets = tweets.dropna(subset=[\"lemmatized\"])\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase `n_neigbors` and/or `min_topic_size` if too many topics:\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=150, \n",
    "    n_components=5, \n",
    "    metric=\"cosine\", \n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "vectorizer_model = CountVectorizer(min_df=50)\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    verbose=True,\n",
    "    nr_topics=\"auto\",\n",
    "    min_topic_size=200,\n",
    "    umap_model=umap_model,\n",
    "    top_n_words=10,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    language=\"english\"\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(tweets.lemmatized.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"BERTopic_model\"\n",
    "topic_model.save(Path(dst, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export topic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table with docs and respective topics\n",
    "df_all_docs = pd.DataFrame({\n",
    "    \"id\": tweets[\"id\"], \n",
    "    \"party\": tweets[\"party\"], \n",
    "    'topic': topics\n",
    "})\n",
    "\n",
    "# save for plotting belief-speaking similarity and truth-seeking\n",
    "# similarity in supplementary figure 5\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"topics_all_docs.csv.gzip\"\n",
    "df_all_docs.to_csv(\n",
    "    Path(dst, fname),\n",
    "    compression=\"gzip\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "topics_per_class = topic_model.topics_per_class(\n",
    "    docs=docs, \n",
    "    topics=topics, \n",
    "    classes=tweets[\"classes_quant\"], \n",
    "    global_tuning=True\n",
    ")\n",
    "fname = \"topics_per_class_ddr.csv\"\n",
    "topics_per_class.to_csv(Path(dst, fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many topics the model found\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"topics_info.csv\"\n",
    "topic_info = pd.DataFrame(topic_model.get_topic_info())\n",
    "topic_info.to_csv(Path(dst, fname), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "fname = \"BERTopic_model\"\n",
    "topic_model = BERTopic.load(Path(src, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the topics (call `x.write_html(path)` to save the graphs)\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap(n_clusters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Topic Modelling (topics over time):\n",
    "topics, probs = topic_model.transform(docs)\n",
    "timestamps = data.created_at.to_list()\n",
    "topics_over_time = topic_model.topics_over_time(docs, topics, timestamps, nr_bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics_per_class(topics_per_class, top_n_topics=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data to create the scattertext plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_ids = []  # insert topic id(s)\n",
    "topics_words = []\n",
    "topic_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in topics_ids:\n",
    "    word_list = []\n",
    "    embedding_list = []\n",
    "    for i in range(\n",
    "        0, 20\n",
    "    ):  # insert how many words you want to display (=< top_n_words in model computation)\n",
    "        word = topic_model.get_topic(id)[i][0]\n",
    "        word_list.append(word)\n",
    "        embedding = topic_model.get_topic(id)[i][1]\n",
    "        embedding_list.append(embedding)\n",
    "    topics_words.append(word_list)\n",
    "    topic_embeddings.append(embedding_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_df = pd.DataFrame()\n",
    "wordcloud_df[\"topic_ids\"] = topics_ids\n",
    "wordcloud_df[\"topic_words\"] = topics_words\n",
    "wordcloud_df[\"topic_embeddings\"] = topic_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = \"../../data/tweets\"\n",
    "fname = \"key_topics.csv\"\n",
    "wordcloud_df = wordcloud_df.set_index([\"topic_ids\"]).apply(pd.Series.explode).reset_index()\n",
    "wordcloud_df.to_csv(Path(dst, fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "260abd549318bbbd6a07931d7c19284ef86ae3047ff26637378d5cbd84eee02c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
