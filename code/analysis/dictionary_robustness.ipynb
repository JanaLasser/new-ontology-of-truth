{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a660bdd-fb3b-40b8-879a-5c599e64f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Jana Lasser & Almog Simchon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3730870a-9e0f-4f32-a089-15105b3d34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8236438e-aefe-493a-9dc8-5b37796b9679",
   "metadata": {},
   "source": [
    "# LME regression NewsGuard score on belief & truth similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95b46b-445b-4b35-8bf2-9a9f39b7f330",
   "metadata": {},
   "source": [
    "**Note**: for this script to work, you will have to run `tweet_collection/wrangle_data.ipynb` with the code for the dictionary robustness analysis included. This will then produce an output file `US_politician_tweets_2010-11-06_to_2022-03-16.csv.gzip` that includes the honesty component similarities for the 100 perturbed dictionary versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5303221-7ca4-44c7-8ef8-cf780723749e",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e538122f-acf5-4f47-a1c2-4e2ffbca93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"US_politician_tweets_2010-11-06_to_2022-03-16.csv.gzip\"\n",
    "cols = [\n",
    "    \"retweeted\", # used to filter out retweets\n",
    "    \"author_id\", # data grouping: independent random variable\n",
    "    \"party\", # characteristic of author: independent fixed variable\n",
    "    \"NG_score\" # dependent variable\n",
    "]\n",
    "# fixed variables from different embeddings and dictionary versions\n",
    "fixed_variables = [f\"avg_truth_score_{i}\" for i in range(100)] + \\\n",
    "                  [f\"avg_belief_score_{i}\" for i in range(100)]\n",
    "cols += fixed_variables\n",
    "\n",
    "tweets = pd.read_csv(\n",
    "    Path(src, fname), \n",
    "    dtype={\"author_id\":str},\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a679ce1a-b613-41e3-ba5d-05dbf51587ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_variables_name_map = \\\n",
    "    {f\"avg_truth_score_{i}\":f\"truth_{i}\" for i in range(100)}\n",
    "for i in range(100):\n",
    "    fixed_variables_name_map[f\"avg_belief_score_{i}\"] = f\"belief_{i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7a2948a0-d731-4d98-92b3-a6a2ef04a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.rename(columns=fixed_variables_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d996f9ca-69b4-44c0-8cc1-5f1987d4571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[tweets[\"retweeted\"] == False] # remove retweets\n",
    "tweets = tweets.drop(columns=[\"retweeted\"])\n",
    "tweets = tweets[tweets[\"party\"].isin([\"Democrat\", \"Republican\"])] # remove independents\n",
    "tweets = tweets.dropna() # remove tweets without NG, belief or truth score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bac5fb0a-661f-445b-9588-58f2c356585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_counts = tweets[\"author_id\"]\\\n",
    "    .value_counts()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"index\":\"author_id\", \"author_id\":\"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bebd1854-78c0-4e61-975a-78b9369441d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out authors with only a single tweet\n",
    "tweets = tweets[tweets[\"author_id\"].isin(tweet_counts[tweet_counts[\"count\"] > 1][\"author_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a60ce256-b7df-4655-8564-964181e8cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"NG\"] = tweets[\"NG_score\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "47d7fd2e-8dbf-4ad6-9d1e-6262479909ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in fixed_variables_name_map.values():\n",
    "    tweets[col] = tweets[col] - tweets[col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c2901105-98b7-47fa-9df1-f3c203db09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618634e5-b38e-4d08-8547-e401f43afc9c",
   "metadata": {},
   "source": [
    "## Calculate estimates with perturbed dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9ae32-d171-4a2f-b86a-223188e6cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    scores = [f\"belief_{i}\", f\"truth_{i}\"]\n",
    "    basic_stats = [\n",
    "        \"Intercept\", \n",
    "        \"party[T.Republican]\", \n",
    "    ]\n",
    "    stats = {\n",
    "        \"belief\":f\"belief_{i}\",\n",
    "        \"truth\":f\"truth_{i}\", \n",
    "        \"belief:party[T.Republican]\":f\"belief_{i}:party[T.Republican]\",\n",
    "        \"truth:party[T.Republican]\":f\"truth_{i}:party[T.Republican]\",\n",
    "        \"belief:truth\":f\"belief_{i}:truth_{i}\",\n",
    "        \"belief:truth:party[T.Republican]\":f\"belief_{i}:truth_{i}:party[T.Republican]\"\n",
    "    }\n",
    "    \n",
    "    md = smf.mixedlm(\n",
    "        f\"NG ~ 1 + belief_{i} * truth_{i} + belief_{i} * truth_{i} * party\",\n",
    "        tweets, \n",
    "        groups=tweets[\"author_id\"],\n",
    "        re_formula=f\"~belief_{i} * truth_{i}\"\n",
    "    )\n",
    "    res = md.fit(method=[\"lbfgs\"], maxiter=30000)\n",
    "    row = {\"run\":i}\n",
    "    for stat in basic_stats:\n",
    "        row[stat + \"_estimate\"] = [res.params[stat]]\n",
    "        row[stat + \"_pval\"] = [res.pvalues[stat]]\n",
    "    for stat in stats.keys():\n",
    "        row[stat + \"_estimate\"] = [res.params[stats[stat]]]\n",
    "        row[stat + \"_pval\"] = [res.pvalues[stats[stat]]]\n",
    "    results = pd.concat([results, pd.DataFrame(row)])\n",
    "results.to_csv(Path(dst, \"LME_results_dictionary_robustness.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
