{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a660bdd-fb3b-40b8-879a-5c599e64f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Jana Lasser & Almog Simchon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3730870a-9e0f-4f32-a089-15105b3d34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8236438e-aefe-493a-9dc8-5b37796b9679",
   "metadata": {},
   "source": [
    "# LME regression NewsGuard score on belief & truth similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95b46b-445b-4b35-8bf2-9a9f39b7f330",
   "metadata": {},
   "source": [
    "**Note**: for this script to work, you will have to run `tweet_collection/wrangle_data.ipynb` with the code for the dictionary robustness analysis included. This will then produce an output file `US_politician_tweets_2010-11-06_to_2022-03-16.csv.gzip` that includes the honesty component similarities for the 100 perturbed dictionary versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5303221-7ca4-44c7-8ef8-cf780723749e",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e538122f-acf5-4f47-a1c2-4e2ffbca93d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1189690/1678003298.py:16: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "src = \"../../data/tweets\"\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"tweets.csv.gzip\"\n",
    "cols = [\n",
    "    \"author_id\", # data grouping: independent random variable\n",
    "    \"party\", # characteristic of author: independent fixed variable\n",
    "    \"NG_score\" # dependent variable\n",
    "]\n",
    "# fixed variables from different embeddings and dictionary versions\n",
    "fixed_variables = [f\"avg_truth_score_{i}\" for i in range(100)] + \\\n",
    "                  [f\"avg_belief_score_{i}\" for i in range(100)]\n",
    "cols += fixed_variables\n",
    "\n",
    "tweets = pd.read_csv(\n",
    "    Path(src, fname), \n",
    "    dtype={\"author_id\":str},\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a679ce1a-b613-41e3-ba5d-05dbf51587ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_variables_name_map = \\\n",
    "    {f\"avg_truth_score_{i}\":f\"truth_{i}\" for i in range(100)}\n",
    "for i in range(100):\n",
    "    fixed_variables_name_map[f\"avg_belief_score_{i}\"] = f\"belief_{i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2948a0-d731-4d98-92b3-a6a2ef04a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.rename(columns=fixed_variables_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d996f9ca-69b4-44c0-8cc1-5f1987d4571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[tweets[\"party\"].isin([\"Democrat\", \"Republican\"])] # remove independents\n",
    "tweets = tweets.dropna() # remove tweets without NG, belief or truth score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac5fb0a-661f-445b-9588-58f2c356585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_counts = tweets[\"author_id\"]\\\n",
    "    .value_counts()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"index\":\"author_id\", \"author_id\":\"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bebd1854-78c0-4e61-975a-78b9369441d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out authors with only a single tweet\n",
    "tweets = tweets[tweets[\"author_id\"].isin(tweet_counts[tweet_counts[\"count\"] > 1][\"author_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a60ce256-b7df-4655-8564-964181e8cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"NG\"] = tweets[\"NG_score\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d7fd2e-8dbf-4ad6-9d1e-6262479909ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in fixed_variables_name_map.values():\n",
    "    tweets[col] = tweets[col] - tweets[col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2901105-98b7-47fa-9df1-f3c203db09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618634e5-b38e-4d08-8547-e401f43afc9c",
   "metadata": {},
   "source": [
    "## Calculate estimates with perturbed dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9ae32-d171-4a2f-b86a-223188e6cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    scores = [f\"belief_{i}\", f\"truth_{i}\"]\n",
    "    basic_stats = [\n",
    "        \"Intercept\", \n",
    "        \"party[T.Republican]\", \n",
    "    ]\n",
    "    stats = {\n",
    "        \"belief\":f\"belief_{i}\",\n",
    "        \"truth\":f\"truth_{i}\", \n",
    "        \"belief:party[T.Republican]\":f\"belief_{i}:party[T.Republican]\",\n",
    "        \"truth:party[T.Republican]\":f\"truth_{i}:party[T.Republican]\",\n",
    "        \"belief:truth\":f\"belief_{i}:truth_{i}\",\n",
    "        \"belief:truth:party[T.Republican]\":f\"belief_{i}:truth_{i}:party[T.Republican]\"\n",
    "    }\n",
    "    \n",
    "    md = smf.mixedlm(\n",
    "        f\"NG ~ 1 + belief_{i} * truth_{i} + belief_{i} * truth_{i} * party\",\n",
    "        tweets, \n",
    "        groups=tweets[\"author_id\"],\n",
    "        re_formula=f\"~belief_{i} * truth_{i}\"\n",
    "    )\n",
    "    res = md.fit(method=[\"lbfgs\"], maxiter=30000)\n",
    "    row = {\"run\":i}\n",
    "    for stat in basic_stats:\n",
    "        row[stat + \"_estimate\"] = [res.params[stat]]\n",
    "        row[stat + \"_pval\"] = [res.pvalues[stat]]\n",
    "    for stat in stats.keys():\n",
    "        row[stat + \"_estimate\"] = [res.params[stats[stat]]]\n",
    "        row[stat + \"_pval\"] = [res.pvalues[stats[stat]]]\n",
    "    results = pd.concat([results, pd.DataFrame(row)])\n",
    "results.to_csv(Path(dst, \"LME_results_dictionary_robustness.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075859ba-7944-4960-a144-4a83cae2b17b",
   "metadata": {},
   "source": [
    "## Calculate estimates with dictionaries reduced by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "826dcf0c-a41c-4f47-ac1e-e8388bd49324",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_honesty_component_scores_glove_reducebyone.csv.gzip\"\n",
    "cols = [\n",
    "    \"id\",\n",
    "    \"author_id\", # data grouping: independent random variable\n",
    "]\n",
    "# fixed variables from different embeddings and dictionary versions\n",
    "fixed_variables = [f\"avg_truth_score_{i}\" for i in range(37)] + \\\n",
    "                  [f\"avg_belief_score_{i}\" for i in range(37)]\n",
    "cols += fixed_variables\n",
    "\n",
    "scores = pd.read_csv(\n",
    "    Path(src, fname), \n",
    "    dtype={\"author_id\":str, \"id\":str},\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    #nrows=100\n",
    ")\n",
    "\n",
    "fname = \"US_politician_tweets_2010-11-06_to_2022-12-31.csv.gzip\"\n",
    "tweets = pd.read_csv(\n",
    "    Path(src, fname), \n",
    "    usecols=[\"id\", \"party\", \"NG_score\", \"avg_belief_score\", \"avg_truth_score\"],\n",
    "    compression=\"gzip\", \n",
    "    dtype={\"id\":str}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "926aaec0-aca0-463f-96f8-d90b3cdcfbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(subset=[\"NG_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "296b2240-dee4-432f-b93b-182c180521ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.merge(tweets, scores, how=\"left\", left_on=\"id\", right_on=\"id\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fb54761-a557-4db7-a34b-94ab52b02da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_variables_name_map = \\\n",
    "    {f\"avg_truth_score_{i}\":f\"truth_{i}\" for i in range(37)}\n",
    "for i in range(37):\n",
    "    fixed_variables_name_map[f\"avg_belief_score_{i}\"] = f\"belief_{i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07d7e598-bef7-4393-992f-a22b96722a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.rename(columns=fixed_variables_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2fb45a08-8210-4683-8150-150e1ac0a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[tweets[\"party\"].isin([\"Democrat\", \"Republican\"])] # remove independents\n",
    "tweets = tweets.dropna() # remove tweets without NG, belief or truth score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e5f0446-3a96-46c5-8ad4-e3b2ad7b9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_counts = tweets[\"author_id\"]\\\n",
    "    .value_counts()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"index\":\"author_id\", \"author_id\":\"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ee11700-2683-4464-a093-447d59b51ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out authors with only a single tweet\n",
    "tweets = tweets[tweets[\"author_id\"].isin(tweet_counts[tweet_counts[\"count\"] > 1][\"author_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1081ae8a-d398-49dc-9238-e5da659ab60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"NG\"] = tweets[\"NG_score\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c57e6db2-2971-4e95-a228-ff45702a5851",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in fixed_variables_name_map.values():\n",
    "    tweets[col] = tweets[col] - tweets[col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4190a747-ff2f-4860-b59b-6755b514665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "133306b6-3732-4fc7-8a61-7a3e463d48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_keywords = pd.read_csv(\"../../data/utilities/truth_seeking_p=0.05_swapped_wn_def_example.csv\") \n",
    "truth_keywords = list(truth_keywords['truth_seeking'])\n",
    "belief_keywords = pd.read_csv(\"../../data/utilities/belief_speaking_p=0.05_swapped_wn_def_example.csv\") \n",
    "belief_keywords = list(belief_keywords['belief_speaking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56180518-140a-4b11-b0ba-ed9c153af596",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_belief = pd.DataFrame()\n",
    "results_truth = pd.DataFrame()\n",
    "\n",
    "for i in range(37):\n",
    "    print(i)\n",
    "    scores = [f\"belief_{i}\", f\"truth_{i}\"]\n",
    "    basic_stats = [\n",
    "        \"Intercept\", \n",
    "        \"party[T.Republican]\", \n",
    "    ]\n",
    "    stats1 = {\n",
    "        \"belief\":f\"belief_{i}\",\n",
    "        \"truth\":\"avg_truth_score\", \n",
    "        \"belief:party[T.Republican]\":f\"belief_{i}:party[T.Republican]\",\n",
    "        \"truth:party[T.Republican]\":f\"avg_truth_score:party[T.Republican]\",\n",
    "        \"belief:truth\":f\"belief_{i}:avg_truth_score\",\n",
    "        \"belief:truth:party[T.Republican]\":f\"belief_{i}:avg_truth_score:party[T.Republican]\"\n",
    "    }\n",
    "    stats2 = {\n",
    "        \"belief\":f\"avg_belief_score\",\n",
    "        \"truth\":f\"truth_{i}\", \n",
    "        \"belief:party[T.Republican]\":f\"avg_belief_score:party[T.Republican]\",\n",
    "        \"truth:party[T.Republican]\":f\"truth_{i}:party[T.Republican]\",\n",
    "        \"belief:truth\":f\"avg_belief_score:truth_{i}\",\n",
    "        \"belief:truth:party[T.Republican]\":f\"avg_belief_score:truth_{i}:party[T.Republican]\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # changing belief-speaking dictionary \n",
    "    row = {\"run\":i, \"keyword\":belief_keywords[i]}\n",
    "    md = smf.mixedlm(\n",
    "        f\"NG ~ 1 + belief_{i} * avg_truth_score + belief_{i} * avg_truth_score * party\",\n",
    "        tweets, \n",
    "        groups=tweets[\"author_id\"],\n",
    "        re_formula=f\"~belief_{i} * avg_truth_score\"\n",
    "    )\n",
    "    res = md.fit(method=[\"lbfgs\"], maxiter=30000)\n",
    "    for stat in basic_stats:\n",
    "        row[stat + \"_belief\" + \"_estimate\"] = [res.params[stat]]\n",
    "        row[stat + \"_belief\" + \"_pval\"] = [res.pvalues[stat]]\n",
    "    for stat in stats1.keys():\n",
    "        row[stat + \"_belief\" + \"_estimate\"] = [res.params[stats1[stat]]]\n",
    "        row[stat + \"_belief\" + \"_pval\"] = [res.pvalues[stats1[stat]]]\n",
    "    results_belief = pd.concat([results_belief, pd.DataFrame(row)])\n",
    "        \n",
    "    # changing truth-seeking dictionary\n",
    "    row = {\"run\":i, \"keyword\":truth_keywords[i]}\n",
    "    md = smf.mixedlm(\n",
    "        f\"NG ~ 1 + avg_belief_score * truth_{i} + avg_belief_score * truth_{i} * party\",\n",
    "        tweets, \n",
    "        groups=tweets[\"author_id\"],\n",
    "        re_formula=f\"~avg_belief_score * truth_{i}\"\n",
    "    )\n",
    "    res = md.fit(method=[\"lbfgs\"], maxiter=30000)\n",
    "    for stat in basic_stats:\n",
    "        row[stat + \"_truth\" + \"_estimate\"] = [res.params[stat]]\n",
    "        row[stat + \"_truth\" + \"_pval\"] = [res.pvalues[stat]]\n",
    "    for stat in stats2.keys():\n",
    "        row[stat + \"_truth\" + \"_estimate\"] = [res.params[stats2[stat]]]\n",
    "        row[stat + \"_truth\" + \"_pval\"] = [res.pvalues[stats2[stat]]]        \n",
    "    results_truth = pd.concat([results_truth, pd.DataFrame(row)])\n",
    "    \n",
    "results_belief.to_csv(Path(dst, \"LME_results_dictionary_belief_reducedbyone.csv\"), index=False)\n",
    "results_truth.to_csv(Path(dst, \"LME_results_dictionary_truth_reducedbyone.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
