{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d21037-1936-4f7d-a997-dc84e609b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Jana Lasser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b082f875-6ca7-4cd4-96ed-da62a556cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# parallelisation functionality\n",
    "from multiprocess import Pool\n",
    "import psutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90888f7e-c32a-47c1-9c36-2c55c210bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = \"../../data/bootstrapping\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d00a25-f70e-4138-98b4-2b48189952a6",
   "metadata": {},
   "source": [
    "# Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5126c8bc-29b4-41a5-ad5a-56c5f8239c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "fname = \"US_politician_tweets_2010-11-06_to_2022-03-16.csv.gzip\"\n",
    "tweets = pd.read_csv(join(src, fname), compression=\"gzip\", parse_dates=[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa47022e-80fd-4c7a-92e4-72a8a91f8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop retweets\n",
    "tweets = tweets[tweets[\"retweeted\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8c0826-2964-4fb4-9948-ace93bf9e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop tweets without honesty component (distill RoBERTa filtering)\n",
    "tweets = tweets.dropna(subset=[\"belief\", \"truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0638b599-810d-4a13-9dbb-8782c39eb716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set tweet creation date as index for easier sampling and aggregation\n",
    "tweets = tweets.set_index(\"created_at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f75b55d-e1b4-4d54-abc2-4a768fad3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop tweets from 2010\n",
    "tweets = tweets[tweets.index.year > 2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f67156-6928-444e-81b4-c6bf2c5dab1e",
   "metadata": {},
   "source": [
    "## Honesty components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0635e0c7-a205-4f2c-861e-bb79eb23a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bootstrap_belief(i):\n",
    "    tweet_sample = tweets.sample(frac=1, replace=True)\n",
    "    belief = tweet_sample[[\"belief\", \"party\"]]\\\n",
    "        .groupby(by=[tweet_sample.index.year, tweet_sample.index.month, \"party\"])\\\n",
    "        .agg([\"sum\", \"count\"])\n",
    "\n",
    "    belief.index.set_names([\"year\", \"month\", \"party\"], inplace=True)\n",
    "    belief = belief.reset_index()\n",
    "    belief.columns = [\"year\", \"month\", \"party\", \"belief_sum\", \"belief_count\"]\n",
    "    belief[\"belief_share\"] = belief[\"belief_sum\"] / belief[\"belief_count\"]\n",
    "    belief[\"run\"] = i\n",
    "    return belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a862cb1-b2e6-46f0-917d-148567340271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [03:34<00:00,  4.67it/s]\n"
     ]
    }
   ],
   "source": [
    "fname = \"belief\"\n",
    "belief_bootstrap = pd.DataFrame()\n",
    "pool = Pool(10)\n",
    "N_bootstrap = 1000\n",
    "\n",
    "for tmp in tqdm(pool.imap_unordered(\n",
    "    func=run_bootstrap_belief, \n",
    "    iterable=range(N_bootstrap)), \n",
    "    total=N_bootstrap):\n",
    "        belief_bootstrap = pd.concat([belief_bootstrap, tmp])\n",
    "belief_bootstrap = belief_bootstrap.reset_index(drop=True)\n",
    "belief_bootstrap.to_csv(join(dst, fname + \".csv\"), index=False)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696e79a3-f8db-431d-8085-4503d443caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bootstrap_truth(i):\n",
    "    tweet_sample = tweets.sample(frac=1, replace=True)\n",
    "    truth = tweet_sample[[\"truth\", \"party\"]]\\\n",
    "        .groupby(by=[tweet_sample.index.year, tweet_sample.index.month, \"party\"])\\\n",
    "        .agg([\"sum\", \"count\"])\n",
    "\n",
    "    truth.index.set_names([\"year\", \"month\", \"party\"], inplace=True)\n",
    "    truth = truth.reset_index()\n",
    "    truth.columns = [\"year\", \"month\", \"party\", \"truth_sum\", \"truth_count\"]\n",
    "    truth[\"truth_share\"] = truth[\"truth_sum\"] / truth[\"truth_count\"]\n",
    "    truth[\"run\"] = i\n",
    "    return truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddef8746-8979-4e14-9ed3-616969a35c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [04:11<00:00,  3.98it/s]\n"
     ]
    }
   ],
   "source": [
    "fname = \"truth\"\n",
    "truth_bootstrap = pd.DataFrame()\n",
    "pool = Pool(10)\n",
    "N_bootstrap = 1000\n",
    "\n",
    "for tmp in tqdm(pool.imap_unordered(\n",
    "    func=run_bootstrap_truth, \n",
    "    iterable=range(N_bootstrap)), \n",
    "    total=N_bootstrap):\n",
    "        truth_bootstrap = pd.concat([truth_bootstrap, tmp])\n",
    "truth_bootstrap = truth_bootstrap.reset_index(drop=True)\n",
    "truth_bootstrap.to_csv(join(dst, fname + \".csv\"), index=False)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd963d7b-8bfe-4d67-8fb3-fad3cff97c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287bf7fb-2583-4756-8dd9-887e6b9671f1",
   "metadata": {},
   "source": [
    "# URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "335c9ab6-10a1-4443-8d8b-7ba5c48fe95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/urls\"\n",
    "fname = \"US_politician_URLs_2010-11-06_to_2022-03-16.csv.gzip\"\n",
    "urls = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    parse_dates=[\"created_at\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d02df2c8-f607-4eca-a3ec-26612ca6997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop retweets\n",
    "urls = urls[urls[\"retweeted\"] == False]\n",
    "\n",
    "# drop entriesl without an honesty component label\n",
    "urls = urls.dropna(subset=[\"belief\", \"truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "682354cb-a400-4d55-9de2-5ef07a73b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[\"has_NG_score\"] = False\n",
    "urls.loc[urls[\"NG_score\"].dropna().index, \"has_NG_score\"] = True\n",
    "urls[\"has_independent_score\"] = False\n",
    "urls.loc[urls[\"independent_unreliable\"].dropna().index, \"has_independent_score\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9982eba-35be-474a-a365-6cc11811ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = urls.set_index(\"created_at\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba6993-d572-45e9-ab4c-333474e7d022",
   "metadata": {},
   "source": [
    "## NewsGuard coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e505925-a919-4c15-81ab-16e19147231d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'domain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'domain'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# remove all entries with urls that point to large social media (twitter, \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# facebook, youtube, instagram), search (google, yahoo) or e-commerce (amazon) \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# sites\u001b[39;00m\n\u001b[1;32m      4\u001b[0m excluded_domains \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwitter.com\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myoutube.com\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook.com\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstagram.com\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcards.twitter.com\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle.com\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myahoo.com\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m urls_clean \u001b[38;5;241m=\u001b[39m urls[\u001b[38;5;241m~\u001b[39m\u001b[43murls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdomain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misin(excluded_domains)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'domain'"
     ]
    }
   ],
   "source": [
    "# remove all entries with urls that point to large social media (twitter, \n",
    "# facebook, youtube, instagram), search (google, yahoo) or e-commerce (amazon) \n",
    "# sites\n",
    "excluded_domains = [\"twitter.com\", \"youtube.com\", \"facebook.com\",\n",
    "            \"instagram.com\", \"cards.twitter.com\", \"google.com\", \"yahoo.com\"]\n",
    "urls_clean = urls[~urls[\"domain\"].isin(excluded_domains)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda14b13-21fd-42cb-9f48-9026f957f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bootstrap_NG_coverage(i):\n",
    "    url_sample = urls_clean.sample(frac=1, replace=True)\n",
    "    coverage = url_sample[[\"has_NG_score\", \"party\"]]\\\n",
    "        .groupby(by=[url_sample.index.year, url_sample.index.month, \"party\"])\\\n",
    "        .agg([\"sum\", \"count\"])\n",
    "\n",
    "    coverage.index.set_names([\"year\", \"month\", \"party\"], inplace=True)\n",
    "    coverage = coverage.reset_index()\n",
    "    coverage.columns = [\"year\", \"month\", \"party\", \"has_NG_score_sum\", \"has_NG_score_count\"]\n",
    "    coverage[\"NG_coverage\"] = coverage[\"has_NG_score_sum\"] / coverage[\"has_NG_score_count\"]\n",
    "    coverage[\"run\"] = i\n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5865906-2e3c-4cfe-8923-e8d3d985bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"NG_coverage\"\n",
    "pool = Pool(10)\n",
    "N_bootstrap = 1000\n",
    "NG_coverage_bootstrap = pd.DataFrame()\n",
    "for tmp in tqdm(pool.imap_unordered(\n",
    "    func=run_bootstrap_NG_coverage, \n",
    "    iterable = range(N_bootstrap)), \n",
    "    total = N_bootstrap):\n",
    "        NG_coverage_bootstrap = pd.concat([NG_coverage_bootstrap, tmp])\n",
    "NG_coverage_bootstrap = NG_coverage_bootstrap.reset_index(drop=True)\n",
    "NG_coverage_bootstrap.to_csv(join(dst, fname + \".csv\"), index=False)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8e66a-c336-48f8-b860-d958f736f855",
   "metadata": {},
   "source": [
    "## Independent list coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f7a68-2980-4c26-bb98-9ba26a57ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bootstrap_independent_coverage(i):\n",
    "    url_sample = urls_clean.sample(frac=1, replace=True)\n",
    "    coverage = url_sample[[\"has_independent_score\", \"party\"]]\\\n",
    "        .groupby(by=[url_sample.index.year, url_sample.index.month, \"party\"])\\\n",
    "        .agg([\"sum\", \"count\"])\n",
    "\n",
    "    coverage.index.set_names([\"year\", \"month\", \"party\"], inplace=True)\n",
    "    coverage = coverage.reset_index()\n",
    "    coverage.columns = [\"year\", \"month\", \"party\", \"has_independent_score_sum\", \"has_independent_score_count\"]\n",
    "    coverage[\"independent_coverage\"] = coverage[\"has_independent_score_sum\"] / coverage[\"has_independent_score_count\"]\n",
    "    coverage[\"run\"] = i\n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d9cdf-0f53-4b99-9cf8-2756016362c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"independent_coverage\"\n",
    "N_bootstrap = 1000\n",
    "pool = Pool(10)\n",
    "independent_coverage_bootstrap = pd.DataFrame()\n",
    "for tmp in tqdm(pool.imap_unordered(\n",
    "    func=run_bootstrap_independent_coverage, \n",
    "    iterable = range(N_bootstrap)), \n",
    "    total = N_bootstrap):\n",
    "        independent_coverage_bootstrap = pd.concat([independent_coverage_bootstrap, tmp])\n",
    "independent_coverage_bootstrap = independent_coverage_bootstrap.reset_index(drop=True)\n",
    "independent_coverage_bootstrap.to_csv(join(dst, fname + \".csv\"), index=False)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ab179-ff7e-4ab3-b7c2-ccf49123e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del urls\n",
    "del urls_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf391c-8e28-4eaf-8788-69393424d18c",
   "metadata": {},
   "source": [
    "# Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdf926-6d32-4338-95e7-964dfde71c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/users\"\n",
    "fname = \"US_politician_accounts_2010-11-06_to_2022-03-16.csv\"\n",
    "users = pd.read_csv(join(src, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b32d2a-0b92-4310-899a-2c212db5b403",
   "metadata": {},
   "source": [
    "## Politifact, NG score & unreliable correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaaabc8-2737-4ff9-929c-acdcc8caeb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bootstrap_reliability_score_correlations(i):\n",
    "    user_sample = users.sample(frac=1, replace=True, random_state=i)\n",
    "    pf_bootstrap = pd.DataFrame({\n",
    "        \"corr_NGScore_pf\":[user_sample[[\"NG_score_mean\", \"pf_score\"]]\\\n",
    "                           .corr().loc[\"pf_score\"][0]],\n",
    "        \"corr_ind_pf\":[np.abs(user_sample[[\"independent_unreliable_share\", \"pf_score\"]]\\\n",
    "                           .corr().loc[\"pf_score\"][0])],\n",
    "        \"corr_NGScore_ind\":[np.abs(user_sample[[\"NG_score_mean\", \"independent_unreliable_share\"]]\\\n",
    "                           .corr().loc[\"independent_unreliable_share\"][0])],\n",
    "        \"corr_NGShare_pf\":[np.abs(user_sample[[\"NG_unreliable_share\", \"pf_score\"]]\\\n",
    "                           .corr().loc[\"pf_score\"][0])],\n",
    "        \"corr_NGShare_ind\":[np.abs(user_sample[[\"NG_unreliable_share\", \"independent_unreliable_share\"]]\\\n",
    "                           .corr().loc[\"independent_unreliable_share\"][0])],\n",
    "        \"corr_NGScore_NGShare\":[np.abs(user_sample[[\"NG_unreliable_share\", \"NG_score_mean\"]]\\\n",
    "                           .corr().loc[\"NG_score_mean\"][0])],\n",
    "        \"corr_NGScore_accuracy\":[np.abs(user_sample[[\"NG_unreliable_share\", \"accuracy_mean\"]]\\\n",
    "                           .corr().loc[\"accuracy_mean\"][0])],\n",
    "        \"corr_NGScore_transparency\":[np.abs(user_sample[[\"NG_unreliable_share\", \"transparency_mean\"]]\\\n",
    "                           .corr().loc[\"transparency_mean\"][0])],\n",
    "        \"run\":[i]\n",
    "    })\n",
    "    return pf_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd531aa-ec28-4c28-8a59-5e7bdf0b35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"user_reliability_score_correlations\"\n",
    "N_bootstrap = 10000\n",
    "pool = Pool(10)\n",
    "pf_bootstrap = pd.DataFrame()\n",
    "for tmp in tqdm(pool.imap_unordered(\n",
    "    func=run_bootstrap_reliability_score_correlations, \n",
    "    iterable = range(N_bootstrap)), \n",
    "    total = N_bootstrap):\n",
    "        pf_bootstrap = pd.concat([pf_bootstrap, tmp])\n",
    "pf_bootstrap = pf_bootstrap.reset_index(drop=True)\n",
    "pf_bootstrap.to_csv(join(dst, fname + \".csv\"), index=False)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585adc53-1b65-4acb-af52-26a10802687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e7dbeb-c16a-4c3c-a6b8-1bfcd91be4e6",
   "metadata": {},
   "source": [
    "# LIWC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27fd905-4082-4ea8-8b46-d307e99bd1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fcc3d-2048-42f5-98c7-2184a552438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"US_politician_tweets_2010-11-06_to_2022-03-16.csv.gzip\"\n",
    "cols = [\"id\", \"author_id\", \"party\", \"created_at\", \"belief\", \"truth\", \"neutral\",\n",
    "        \"LIWC_authentic\", \"LIWC_analytic\", \"LIWC_moral\", \n",
    "        \"LIWC_emo_pos\", \"LIWC_emo_neg\"]\n",
    "tweets = pd.read_csv(\n",
    "    join(src, fname), \n",
    "    compression=\"gzip\",\n",
    "    parse_dates=[\"created_at\"],\n",
    "    dtype={\"id\":str, \"author_id\":str},\n",
    "    usecols=cols\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d454bc-9a2e-4782-bd99-f1589d16171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(subset=[\"belief\", \"truth\", \"neutral\"])\n",
    "for col in [\"belief\", \"truth\", \"neutral\"]:\n",
    "    tweets[col] = tweets[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283d84f-0a54-4bde-b750-995e60be6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"honesty_component\"] = np.nan\n",
    "tweets.loc[tweets[tweets[\"belief\"] == 1].index, \"honesty_component\"] = \"belief\"\n",
    "tweets.loc[tweets[tweets[\"truth\"] == 1].index, \"honesty_component\"] = \"truth\"\n",
    "tweets.loc[tweets[tweets[\"neutral\"] == 1].index, \"honesty_component\"] = \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd82c7c-120a-4aec-a502-4278bad37477",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"honesty_component\", \"LIWC_analytic\", \"LIWC_authentic\", \"LIWC_moral\",\n",
    "        \"LIWC_emo_pos\", \"LIWC_emo_neg\"]\n",
    "tweets[cols]\\\n",
    "    .groupby([\"honesty_component\"])\\\n",
    "    .agg([\"mean\", \"std\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821812b-29a3-499f-9c1f-16eaf39ab758",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.set_index(\"created_at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36495468-992f-417e-beeb-23be61a70fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bootstrap_LIWC(i):\n",
    "    cols = [\"LIWC_analytic\", \"LIWC_authentic\", \"LIWC_moral\",\n",
    "            \"LIWC_emo_pos\", \"LIWC_emo_neg\"]\n",
    "    newcols = [\n",
    "        \"year\", \"month\", \"party\", \n",
    "        \"LIWC_analytic_sum\", \"LIWC_analytic_count\",\n",
    "        \"LIWC_authentic_sum\", \"LIWC_authentic_count\",\n",
    "        \"LIWC_moral_sum\", \"LIWC_moral_count\",\n",
    "        \"LIWC_emo_pos_sum\", \"LIWC_emo_pos_count\",\n",
    "        \"LIWC_emo_neg_sum\", \"LIWC_emo_neg_count\"\n",
    "    ]\n",
    "    \n",
    "    df_sample = tweets.sample(frac=1, replace=True, random_state=i)\n",
    "    grouping = df_sample[cols + [\"party\"]]\\\n",
    "        .groupby(by=[df_sample.index.year, df_sample.index.month, \"party\"])\\\n",
    "        .agg([\"sum\", \"count\"])\n",
    "\n",
    "    grouping.index.set_names([\"year\", \"month\", \"party\"], inplace=True)\n",
    "    grouping = grouping.reset_index()\n",
    "    grouping.columns = newcols\n",
    "    for col in cols:\n",
    "        grouping[f\"{col}_share\"] = grouping[f\"{col}_sum\"] / \\\n",
    "            grouping[f\"{col}_count\"]\n",
    "    grouping[\"run\"] = i\n",
    "    \n",
    "    belief_subset = df_sample[df_sample[\"belief\"] == 1]\n",
    "    truth_subset = df_sample[df_sample[\"truth\"] == 1]\n",
    "    neutral_subset = df_sample[df_sample[\"neutral\"] == 1]\n",
    "    \n",
    "    belief_grouping = belief_subset[cols + [\"party\"]]\\\n",
    "        .groupby(by=[belief_subset.index.year, belief_subset.index.month, \"party\"])\\\n",
    "        .agg([\"sum\", \"count\"])\n",
    "    belief_grouping.index.set_names([\"year\", \"month\", \"party\"], inplace=True)\n",
    "    belief_grouping = belief_grouping.reset_index()\n",
    "    belief_grouping.columns = newcols\n",
    "    for col in cols:\n",
    "        belief_grouping[f\"{col}_share\"] = belief_grouping[f\"{col}_sum\"] / \\\n",
    "            belief_grouping[f\"{col}_count\"]\n",
    "    belief_grouping[\"run\"] = i\n",
    "    \n",
    "    truth_grouping = truth_subset[cols + [\"party\"]]\\\n",
    "        .groupby(by=[truth_subset.index.year, truth_subset.index.month, \"party\"])\\\n",
    "        .agg([\"sum\", \"count\"])\n",
    "    truth_grouping.index.set_names([\"year\", \"month\", \"party\"], inplace=True)\n",
    "    truth_grouping = truth_grouping.reset_index()\n",
    "    truth_grouping.columns = newcols\n",
    "    for col in cols:\n",
    "        truth_grouping[f\"{col}_share\"] = truth_grouping[f\"{col}_sum\"] / \\\n",
    "            truth_grouping[f\"{col}_count\"]\n",
    "    truth_grouping[\"run\"] = i\n",
    "    \n",
    "    neutral_grouping = neutral_subset[cols + [\"party\"]]\\\n",
    "        .groupby(by=[neutral_subset.index.year, neutral_subset.index.month, \"party\"])\\\n",
    "        .agg([\"sum\", \"count\"])\n",
    "    neutral_grouping.index.set_names([\"year\", \"month\", \"party\"], inplace=True)\n",
    "    neutral_grouping = neutral_grouping.reset_index()\n",
    "    neutral_grouping.columns = newcols\n",
    "    for col in cols:\n",
    "        neutral_grouping[f\"{col}_share\"] = neutral_grouping[f\"{col}_sum\"] / \\\n",
    "            neutral_grouping[f\"{col}_count\"]\n",
    "    neutral_grouping[\"run\"] = i\n",
    "    \n",
    "    return grouping, belief_grouping, truth_grouping, neutral_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab94a13b-e3eb-4c3f-928f-f414f2c3dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC_bootstrap = pd.DataFrame()\n",
    "LIWC_belief_bootstrap = pd.DataFrame()\n",
    "LIWC_truth_bootstrap = pd.DataFrame()\n",
    "LIWC_neutral_bootstrap = pd.DataFrame()\n",
    "pool = Pool(10)\n",
    "N_bootstrap = 1000\n",
    "\n",
    "for tmp1, tmp2, tmp3, tmp4 in tqdm(pool.imap_unordered(\n",
    "    func=run_bootstrap_LIWC, \n",
    "    iterable=range(N_bootstrap)), \n",
    "    total=N_bootstrap):\n",
    "        LIWC_bootstrap = pd.concat([LIWC_bootstrap, tmp1])\n",
    "        LIWC_belief_bootstrap = pd.concat([LIWC_belief_bootstrap, tmp2])\n",
    "        LIWC_truth_bootstrap = pd.concat([LIWC_truth_bootstrap, tmp3])\n",
    "        LIWC_neutral_bootstrap = pd.concat([LIWC_neutral_bootstrap, tmp4])\n",
    "        \n",
    "LIWC_bootstrap = LIWC_bootstrap.reset_index(drop=True)\n",
    "LIWC_belief_bootstrap = LIWC_belief_bootstrap.reset_index(drop=True)\n",
    "LIWC_truth_bootstrap = LIWC_truth_bootstrap.reset_index(drop=True)\n",
    "LIWC_neutral_bootstrap = LIWC_neutral_bootstrap.reset_index(drop=True)\n",
    "\n",
    "fname = \"LIWC\"\n",
    "LIWC_bootstrap.to_csv(join(dst, fname + \".csv\"), index=False)\n",
    "fname = \"LIWC_belief\"\n",
    "LIWC_belief_bootstrap.to_csv(join(dst, fname + \".csv\"), index=False)\n",
    "fname = \"LIWC_truth\"\n",
    "LIWC_truth_bootstrap.to_csv(join(dst, fname + \".csv\"), index=False)\n",
    "fname = \"LIWC_neutral\"\n",
    "LIWC_neutral_bootstrap.to_csv(join(dst, fname + \".csv\"), index=False)\n",
    "pool.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
