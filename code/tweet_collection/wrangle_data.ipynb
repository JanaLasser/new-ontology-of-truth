{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316acf0-df86-4849-bfce-ae80cceac5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Jana Lasser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d70086-b0cd-471d-867d-21e782483b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139da757-f9f3-4839-b4e8-224adf5dafd7",
   "metadata": {},
   "source": [
    "# Create a URL data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bc1b3-3813-489c-8aa9-266ddf21b8fe",
   "metadata": {},
   "source": [
    "## Expand URL lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d47cd12-d37e-48b2-9c2a-762a6cedc62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned timeline-data\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_clean.csv.gzip\"\n",
    "cols = [\"id\", \"author_id\", \"created_at\", \"expanded_urls\",\n",
    "        \"retweeted\", \"quoted\", \"reply\"]\n",
    "tweets = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ffcd134-eaad-4cc9-b662-6f0067f2d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the URL lists\n",
    "tweets[\"expanded_urls\"] = tweets[\"expanded_urls\"].fillna(\"[]\")\n",
    "tweets[\"expanded_urls\"] = tweets[\"expanded_urls\"].apply(lambda x: eval(x))\n",
    "tweets[\"has_url\"] = tweets[\"expanded_urls\"].apply(lambda x: len(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696f9f53-bd91-4e8c-adb7-592e7199f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"N_urls\"] = tweets[\"expanded_urls\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb66c73-f676-4875-ad0c-2a46a99cc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand only entries with multiple URLs\n",
    "multiple_urls = tweets[tweets[\"N_urls\"] > 1]\n",
    "expanded_urls = pd.DataFrame()\n",
    "for idx, entry in multiple_urls.iterrows():\n",
    "    row = {key:val for key, val in entry.items()}\n",
    "    expanded_urls = pd.concat([expanded_urls, pd.DataFrame(row)])\n",
    "    \n",
    "expanded_urls = expanded_urls.set_index(\"id\")\n",
    "urls = tweets.copy()\n",
    "urls = urls.set_index(\"id\")\n",
    "# drop entries with mutiple URLs\n",
    "urls = urls.drop(multiple_urls[\"id\"].values)\n",
    "# add expanded entries with one line for each URL\n",
    "urls = pd.concat([urls, expanded_urls])\n",
    "urls = urls.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03594ce-f9b9-43f3-9b95-fa5ecf9dfac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5072662"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910bb11-3cf4-4fec-a136-795b73229929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, some URLs are stored as singular entries of a list, and some as string.\n",
    "# empty entries are stored as empty list. Below we streamline URL entries such\n",
    "# that every entry is a single string\n",
    "def extract_URL_from_list(entry):\n",
    "    if len(entry) == 0:\n",
    "        return np.nan\n",
    "    elif len(entry) == 1:\n",
    "        return entry[0]\n",
    "    else:\n",
    "        return entry\n",
    "    \n",
    "urls[\"expanded_urls\"] = urls[\"expanded_urls\"].apply(extract_URL_from_list)\n",
    "urls = urls.rename(columns={\"expanded_urls\":\"url\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a37e86-396c-4706-ac02-0b3f4f2c5ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 338509 duplicate URL entries\n"
     ]
    }
   ],
   "source": [
    "# some tweets contain the same URL twice. We drop these\n",
    "N = len(urls)\n",
    "urls = urls.drop_duplicates(subset=[\"id\", \"url\"])\n",
    "print(f\"dropped {N - len(urls)} duplicate URL entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e5cb331-3aee-4fe9-b6ea-d8ec5b0d35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ba76e8-09a0-4f2e-bd7c-198a30a14e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outcome\n",
    "dst = \"../../data/urls\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_clean_urls.csv.gzip\"\n",
    "urls.to_csv(join(dst, fname), compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9287984-bfed-41cd-b853-226df27367c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data frame with the expanded URLs\n",
    "src = \"../../data/urls\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_clean_urls.csv.gzip\"\n",
    "cols = [\"id\", \"author_id\", \"created_at\", \"url\", \"retweeted\",\n",
    "        \"quoted\", \"reply\", \"has_url\"]\n",
    "urls = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    parse_dates=[\"created_at\"],\n",
    "    dtype={\"author_id\":str, \"id\":str}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f16ba50-72da-49c2-998c-883580cadb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4734153"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07371d18-7280-4dc1-9723-fc500507ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the public metrics information for the collected tweets\n",
    "# note: this is not needed for the analysis in this publication, but might be\n",
    "# handy for analyses of tweet engagement metrics\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_clean.csv.gzip\"\n",
    "tweet_metrics = pd.read_csv(join(src, fname),\n",
    "                 compression=\"gzip\",\n",
    "                 usecols=[\"id\", \"retweet_count\",\n",
    "                          \"reply_count\", \"like_count\", \"quote_count\"],\n",
    "                dtype={\"id\":str})\n",
    "tweet_metrics = tweet_metrics.drop_duplicates(subset=\"id\")\n",
    "# merge the tweet metrics with the tweet data frame\n",
    "urls = pd.merge(urls, tweet_metrics, how=\"left\", left_on=\"id\", right_on=\"id\")\n",
    "del tweet_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d582d2-3902-4505-b3f2-912132db85ba",
   "metadata": {},
   "source": [
    "## Add unraveled URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a307d6-8c0f-4f81-943f-2224dde5809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of originally shortened URLs with their expansions to their true\n",
    "# destination\n",
    "src = \"../../data/urls\"\n",
    "fname = \"US_unraveled_urls.csv.xz\"\n",
    "unraveled_urls = pd.read_csv(\n",
    "    join(src, fname), \n",
    "    compression=\"xz\",\n",
    "    usecols=[\"url\", \"unraveled_url\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e27855-f091-47c4-a863-39157079b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add URL information\n",
    "urls = pd.merge(\n",
    "    urls,\n",
    "    unraveled_urls[[\"url\", \"unraveled_url\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"url\",\n",
    "    right_on=\"url\"\n",
    ")\n",
    "\n",
    "# add indicator of whether the URL was originally shortened\n",
    "urls[\"shortened_url\"] = False\n",
    "urls.loc[urls[\"unraveled_url\"].dropna().index, \"shortened_url\"] = True\n",
    "\n",
    "# replace the shortened URL with the unraveled URL\n",
    "urls.loc[urls[\"unraveled_url\"].dropna().index, \"url\"] = \\\n",
    "    urls.loc[urls[\"unraveled_url\"].dropna().index, \"unraveled_url\"]\n",
    "urls = urls.drop(columns=[\"unraveled_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb618ca-2d99-4b12-b55d-34cba20edadf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL https\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL https\n",
      "found malformed URL http\n"
     ]
    }
   ],
   "source": [
    "# extract the domain from the URL. Note: a few \"found malformed URL\" warnings\n",
    "# are acceptable\n",
    "def extract_domain(url):\n",
    "    '''Given an ULR, extracts the domain name in the form XXXXX.YY'''\n",
    "    if url != url:\n",
    "        return np.nan\n",
    "    # reformat entries that have the domain after a general name in parantheses\n",
    "    if url.find('(') > 0:\n",
    "        url = url.split('(')[-1]\n",
    "        url = url.strip(')')\n",
    "    # trailing \"/\" and spaces\n",
    "    url = url.strip('/').strip()\n",
    "    # transform all domains to lowercase\n",
    "    url = url.lower()\n",
    "    # remove any white spaces\n",
    "    url = url.replace(' ', '')\n",
    "    # if present: remove the protocol\n",
    "    if url.startswith((\"http\", \"https\")):\n",
    "        try:\n",
    "            url = url.split('//')[1]\n",
    "        except IndexError:\n",
    "            print(f\"found malformed URL {url}\")\n",
    "            return np.nan\n",
    "    # remove \"www.\" \n",
    "    url = url.replace('www.', '')\n",
    "    url = url.split(\"/\")[0]\n",
    "    return url\n",
    "\n",
    "urls[\"domain\"] = urls[\"url\"].apply(extract_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beecaea6-0097-46bd-81ba-447d54aedbe7",
   "metadata": {},
   "source": [
    "## Add NewsGuard nutrition scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bd17d-6a55-4776-bb34-082cf521baf6",
   "metadata": {},
   "source": [
    "Newsguard rating threshold to label a domain as \"unreliable\": 60 (see [description](https://www.newsguardtech.com/ratings/rating-process-criteria/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b883f36-4d22-4e78-ae0d-3b5efa10fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27eb7a1-a3c0-4b14-8cd3-3b003a6d0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the nutrition labels\n",
    "src = \"../../data/utilities/\"\n",
    "fname = \"NewsGuard_labels.csv\"\n",
    "cols = [\"Domain\", \"Score\", \"Last Updated\"]\n",
    "NG_scores = pd.read_csv(join(src, fname), usecols=cols)\n",
    "# if more than one score exists for the same domain, keep the most recent one\n",
    "NG_scores = NG_scores.sort_values(by=[\"Domain\",\"Last Updated\"], ascending=False)\n",
    "NG_scores = NG_scores.drop_duplicates(subset=[\"Domain\"])\n",
    "NG_scores = NG_scores.rename(columns={\"Domain\":\"domain\", \"Score\":\"NG_score\"})\n",
    "NG_scores = NG_scores.drop(columns=[\"Last Updated\"])\n",
    "\n",
    "# threshold scores at various cutoffs to define untrustworthy domains\n",
    "NG_scores[\"NG_unreliable\"] = 0\n",
    "NG_scores.loc[NG_scores[NG_scores[\"NG_score\"] < threshold].index, \"NG_unreliable\"] = 1\n",
    "\n",
    "# add the nutrition information to the tweet data table\n",
    "urls = pd.merge(urls, NG_scores,\n",
    "         left_on=\"domain\", right_on=\"domain\", how=\"left\")\n",
    "del NG_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4e71e-2b3e-4443-a9a7-aef9deef614a",
   "metadata": {},
   "source": [
    "## Add alternative trustworthiness labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a4a1fe-f8c2-4dd9-a93d-db0c7cadc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of independently compiled trustworthiness labels for \n",
    "# news sources\n",
    "src = \"../../data/utilities\"\n",
    "fname = \"independent_labels.csv\"\n",
    "alt_labels = pd.read_csv(join(src, fname))\n",
    "alt_labels = alt_labels.rename(columns = {\n",
    "    \"type\":\"independent_unreliable\", \n",
    "    \"url\":\"domain\"})\n",
    "\n",
    "# convert reliability labels to binary\n",
    "alt_labels[\"independent_unreliable\"] = alt_labels[\"independent_unreliable\"]\\\n",
    "    .replace({\"reliable\":0, \"unreliable\":1})\n",
    "\n",
    "# merge with the tweet data table\n",
    "urls = pd.merge(urls, alt_labels[[\"accuracy\", \"transparency\", \n",
    "        \"independent_unreliable\", \"domain\"]], how=\"left\", left_on=\"domain\",\n",
    "         right_on=\"domain\")\n",
    "del alt_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b062d-4c8b-494c-b9a5-c1795971d885",
   "metadata": {},
   "source": [
    "## Tweet length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc2f8d2-c28b-4103-b0a4-a16c780b34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned timeline-data\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_clean.csv.gzip\"\n",
    "cols = [\"id\", \"text\"]\n",
    "texts = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    dtype={\"id\":str, \"text\":str}\n",
    ")\n",
    "\n",
    "texts[\"tweet_length\"] = texts[\"text\"].apply(lambda x: len(x))\n",
    "\n",
    "urls = pd.merge(\n",
    "    urls,\n",
    "    texts[[\"id\", \"tweet_length\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"id\",\n",
    "    right_on=\"id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae920e-36fa-413c-b46c-e005aa0c64b4",
   "metadata": {},
   "source": [
    "## Add truth seeking & belief speaking scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abe90f-18f8-4e9b-975e-bd20d59ae219",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dafdca3-1193-45a2-b452-768b2324cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the embedding scores for belief-speaking and truth-seeking\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_honesty_component_scores_glove.csv.gzip\"\n",
    "honesty_scores = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    dtype={\"id\":str}, \n",
    "    compression=\"gzip\"\n",
    ").rename(columns={\"avg_truth_score\":\"avg_truth_score_raw\", \"avg_belief_score\":\"avg_belief_score_raw\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a354d3d7-286f-46e1-afcc-502b83008051",
   "metadata": {},
   "outputs": [],
   "source": [
    "honesty_scores = pd.merge(\n",
    "    honesty_scores,\n",
    "    urls[[\"id\", \"tweet_length\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"id\",\n",
    "    right_on=\"id\"\n",
    ")\n",
    "honesty_scores = honesty_scores.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaf5f541-d41f-41ca-bb48-e31858ce0172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belief-speaking slope: 0.0009353730302445349, intercept: 0.36703874244674656\n",
      "truth-seeking slope: 0.0010236247437594504, intercept: 0.3052734641526922\n"
     ]
    }
   ],
   "source": [
    "# correct the similarity scores for tweet-length effects\n",
    "slope_belief, intercept_belief, rval_belief, pval_belief, stderr_belief = \\\n",
    "    linregress(honesty_scores[\"tweet_length\"], honesty_scores[\"avg_belief_score_raw\"])\n",
    "print(f\"belief-speaking slope: {slope_belief}, intercept: {intercept_belief}\")\n",
    "\n",
    "def predict_belief_similarity(tweet_length):\n",
    "    return intercept_belief + slope_belief * tweet_length\n",
    "\n",
    "slope_truth, intercept_truth, rval_truth, pval_truth, stderr_truth = \\\n",
    "    linregress(honesty_scores[\"tweet_length\"], honesty_scores[\"avg_truth_score_raw\"])\n",
    "print(f\"truth-seeking slope: {slope_truth}, intercept: {intercept_truth}\")\n",
    "\n",
    "def predict_truth_similarity(tweet_length):\n",
    "    return intercept_truth + slope_truth * tweet_length\n",
    "\n",
    "honesty_scores[\"avg_belief_score\"] = honesty_scores\\\n",
    "    .apply(lambda x: x[\"avg_belief_score_raw\"] - predict_belief_similarity(x[\"tweet_length\"]), axis=1)\n",
    "\n",
    "honesty_scores[\"avg_truth_score\"] = honesty_scores\\\n",
    "    .apply(lambda x: x[\"avg_truth_score_raw\"] - predict_truth_similarity(x[\"tweet_length\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e437f3d0-a725-4d7a-be71-e4ccc78a0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the raw and corrected scores with the url data frame\n",
    "cols = [\"id\", \"avg_truth_score_raw\", \"avg_truth_score\", \"avg_belief_score_raw\", \"avg_belief_score\"]\n",
    "urls = pd.merge(\n",
    "    honesty_scores[cols], \n",
    "    urls, \n",
    "    how=\"right\", \n",
    "    left_on=\"id\", \n",
    "    right_on=\"id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998dfc7-486f-4764-8cfe-f3c54ea9c411",
   "metadata": {},
   "source": [
    "### Add truth seeking & belief speaking scores for dictionary bootstraps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a727bf35-17d7-4d31-9af9-b3c16bc9f7ab",
   "metadata": {},
   "source": [
    "**Note** include this code if you have generated honesty component similarities using the bootstrapped dictionaries by running `label_lexicon_loop.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52feccbc-65b9-4192-98ff-356edf0b2407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsrc = \"../../data/tweets\"\\nfname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_honesty_component_scores_glove_bootstrap.csv.gzip\"\\nhonesty_scores_bootstrap = pd.read_csv(\\n    join(src, fname),\\n    compression=\"gzip\",\\n    dtype={\"id\":str},\\n)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_honesty_component_scores_glove_bootstrap.csv.gzip\"\n",
    "honesty_scores_bootstrap = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    dtype={\"id\":str},\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43138738-7ccf-4a4a-b4e4-0021232365ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhonesty_scores_bootstrap = pd.merge(\\n    honesty_scores_bootstrap,\\n    urls[[\"id\", \"tweet_length\"]],\\n    how=\"left\",\\n    left_on=\"id\",\\n    right_on=\"id\"\\n)\\nhonesty_scores_bootstrap = honesty_scores_bootstrap.dropna()\\nhonesty_scores_bootstrap = honesty_scores_bootstrap.drop_duplicates(subset=[\"id\"])\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "honesty_scores_bootstrap = pd.merge(\n",
    "    honesty_scores_bootstrap,\n",
    "    urls[[\"id\", \"tweet_length\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"id\",\n",
    "    right_on=\"id\"\n",
    ")\n",
    "honesty_scores_bootstrap = honesty_scores_bootstrap.dropna()\n",
    "honesty_scores_bootstrap = honesty_scores_bootstrap.drop_duplicates(subset=[\"id\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b189345b-d6f3-4a20-8fe6-645d8458ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    honesty_scores_bootstrap[f\"avg_belief_score_{i}\"] = honesty_scores_bootstrap\\\n",
    "        .apply(lambda x: x[f\"avg_belief_score_{i}\"] - predict_belief_similarity(x[\"tweet_length\"]), axis=1)    \n",
    "    honesty_scores_bootstrap[f\"avg_truth_score_{i}\"] = honesty_scores_bootstrap\\\n",
    "        .apply(lambda x: x[f\"avg_truth_score_{i}\"] - predict_truth_similarity(x[\"tweet_length\"]), axis=1)\n",
    "\n",
    "honesty_scores_bootstrap = honesty_scores_bootstrap.drop(columns=[\"tweet_length\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "823f8fbe-fc0a-4ed4-a820-b00b050be0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "urls = pd.merge(\n",
    "    honesty_scores_bootstrap, \n",
    "    urls, \n",
    "    how=\"right\", \n",
    "    left_on=\"id\", \n",
    "    right_on=\"id\"\n",
    ")\n",
    "del honesty_scores_bootstrap\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432d92b-baeb-4fed-8c7f-7570e5f6dcc2",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9a01f10-6fe2-438c-873e-3105665dbb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the embedding scores for belief-speaking and truth-seeking\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_honesty_component_scores_word2vec.csv.gzip\"\n",
    "honesty_scores = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    dtype={\"id\":str}, \n",
    "    compression=\"gzip\"\n",
    ")\n",
    "honesty_scores = honesty_scores.rename(columns={\n",
    "    \"avg_truth_score\":\"avg_truth_score_word2vec_raw\",\n",
    "    \"avg_belief_score\":\"avg_belief_score_word2vec_raw\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8e29816-74a7-4c0a-a338-a5a1bde6d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "honesty_scores = pd.merge(\n",
    "    honesty_scores,\n",
    "    urls[[\"id\", \"tweet_length\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"id\",\n",
    "    right_on=\"id\"\n",
    ")\n",
    "honesty_scores = honesty_scores.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a6fb781-9fe2-4f19-aa08-28de143069ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belief-speaking slope: 0.0005525060956405117, intercept: 0.5790686291835863\n",
      "truth-seeking slope: 0.0006087550972715038, intercept: 0.516270415882894\n"
     ]
    }
   ],
   "source": [
    "# correct the similarity scores for tweet-length effects\n",
    "slope_belief, intercept_belief, rval_belief, pval_belief, stderr_belief = \\\n",
    "    linregress(honesty_scores[\"tweet_length\"], honesty_scores[\"avg_belief_score_word2vec_raw\"])\n",
    "print(f\"belief-speaking slope: {slope_belief}, intercept: {intercept_belief}\")\n",
    "\n",
    "def predict_belief_similarity(tweet_length):\n",
    "    return intercept_belief + slope_belief * tweet_length\n",
    "\n",
    "slope_truth, intercept_truth, rval_truth, pval_truth, stderr_truth = \\\n",
    "    linregress(honesty_scores[\"tweet_length\"], honesty_scores[\"avg_truth_score_word2vec_raw\"])\n",
    "print(f\"truth-seeking slope: {slope_truth}, intercept: {intercept_truth}\")\n",
    "\n",
    "def predict_truth_similarity(tweet_length):\n",
    "    return intercept_truth + slope_truth * tweet_length\n",
    "\n",
    "honesty_scores[\"avg_belief_score_word2vec\"] = honesty_scores\\\n",
    "    .apply(lambda x: x[\"avg_belief_score_word2vec_raw\"] - predict_belief_similarity(x[\"tweet_length\"]), axis=1)\n",
    "\n",
    "honesty_scores[\"avg_truth_score_word2vec\"] = honesty_scores\\\n",
    "    .apply(lambda x: x[\"avg_truth_score_word2vec_raw\"] - predict_truth_similarity(x[\"tweet_length\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fedacab7-d422-4084-a2f7-2e7855060020",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"id\", \"avg_truth_score_word2vec_raw\", \"avg_truth_score_word2vec\", \"avg_belief_score_word2vec_raw\", \"avg_belief_score_word2vec\"]\n",
    "urls = pd.merge(\n",
    "    honesty_scores[cols], \n",
    "    urls, \n",
    "    how=\"right\", \n",
    "    left_on=\"id\", \n",
    "    right_on=\"id\"\n",
    ")\n",
    "del honesty_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afff497-1e97-4ace-878e-db801c38432a",
   "metadata": {},
   "source": [
    "### fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff80a9ef-e4c5-4029-af03-f0b1904586d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the embedding scores for belief-speaking and truth-seeking\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_honesty_component_scores_fasttext.csv.gzip\"\n",
    "honesty_scores = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    dtype={\"id\":str}, \n",
    "    compression=\"gzip\"\n",
    ")\n",
    "honesty_scores = honesty_scores.rename(columns={\n",
    "    \"avg_truth_score\":\"avg_truth_score_fasttext_raw\",\n",
    "    \"avg_belief_score\":\"avg_belief_score_fasttext_raw\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c643f4cd-94cc-4001-9969-a3005c02be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "honesty_scores = pd.merge(\n",
    "    honesty_scores,\n",
    "    urls[[\"id\", \"tweet_length\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"id\",\n",
    "    right_on=\"id\"\n",
    ")\n",
    "honesty_scores = honesty_scores.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08d884b4-fa7b-4829-b84d-672e4fe071c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "honesty_scores = honesty_scores.drop_duplicates(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83815fde-a876-44bc-b21e-69ce903b324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belief-speaking slope: 0.0005501307210788646, intercept: 0.3800728900605277\n",
      "truth-seeking slope: 0.0005520439469570941, intercept: 0.34329250235666736\n"
     ]
    }
   ],
   "source": [
    "# correct the similarity scores for tweet-length effects\n",
    "slope_belief, intercept_belief, rval_belief, pval_belief, stderr_belief = \\\n",
    "    linregress(honesty_scores[\"tweet_length\"], honesty_scores[\"avg_belief_score_fasttext_raw\"])\n",
    "print(f\"belief-speaking slope: {slope_belief}, intercept: {intercept_belief}\")\n",
    "\n",
    "def predict_belief_similarity(tweet_length):\n",
    "    return intercept_belief + slope_belief * tweet_length\n",
    "\n",
    "slope_truth, intercept_truth, rval_truth, pval_truth, stderr_truth = \\\n",
    "    linregress(honesty_scores[\"tweet_length\"], honesty_scores[\"avg_truth_score_fasttext_raw\"])\n",
    "print(f\"truth-seeking slope: {slope_truth}, intercept: {intercept_truth}\")\n",
    "\n",
    "def predict_truth_similarity(tweet_length):\n",
    "    return intercept_truth + slope_truth * tweet_length\n",
    "\n",
    "honesty_scores[\"avg_belief_score_fasttext\"] = honesty_scores\\\n",
    "    .apply(lambda x: x[\"avg_belief_score_fasttext_raw\"] - predict_belief_similarity(x[\"tweet_length\"]), axis=1)\n",
    "\n",
    "honesty_scores[\"avg_truth_score_fasttext\"] = honesty_scores\\\n",
    "    .apply(lambda x: x[\"avg_truth_score_fasttext_raw\"] - predict_truth_similarity(x[\"tweet_length\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1537241-dac7-4822-bbc9-1d2bbcda1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"id\", \"avg_truth_score_fasttext_raw\", \"avg_truth_score_fasttext\", \"avg_belief_score_fasttext_raw\", \"avg_belief_score_fasttext\"]\n",
    "urls = pd.merge(\n",
    "    honesty_scores[cols], \n",
    "    urls, \n",
    "    how=\"right\", \n",
    "    left_on=\"id\", \n",
    "    right_on=\"id\"\n",
    ")\n",
    "del honesty_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e8610-dd79-4384-a4c9-962ab6628cf1",
   "metadata": {},
   "source": [
    "## Add party affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8baa890d-8c48-4c33-98ea-e7655f053d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/users\"\n",
    "fname = \"US_politician_twitter_accounts_clean.csv\"\n",
    "party_affiliation = pd.read_csv(\n",
    "    join(src, fname), \n",
    "    usecols=[\"author_id\", \"party\", \"name\", \"handle\"],\n",
    "    dtype={\"author_id\":str}\n",
    ")\n",
    "urls = pd.merge(urls, party_affiliation, how=\"left\", left_on=\"author_id\",\n",
    "    right_on=\"author_id\")\n",
    "del party_affiliation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df744784-ba6f-4691-ba80-3b74a9c30075",
   "metadata": {},
   "source": [
    "## Export URLs for article scraping & statistical modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddbcc04c-f946-4d8f-bace-70449904ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the list of all URLs for article text straping\n",
    "dst = \"../../data/articles/\"\n",
    "fname = \"url_list_for_article_scraping.csv.gzip\"\n",
    "url_export = urls[[\"domain\", \"url\", \"party\"]].copy()\n",
    "url_export = url_export.drop_duplicates().dropna(subset=[\"url\"])\n",
    "url_export.to_csv(join(dst, fname), index=False, compression=\"gzip\")\n",
    "\n",
    "fname = \"url_NG_scores.csv.gzip\"\n",
    "url_export = urls[[\"url\", \"NG_score\", \"party\"]].copy()\n",
    "url_export = url_export.drop_duplicates().dropna(subset=[\"url\"])\n",
    "url_export.to_csv(join(dst, fname), index=False, compression=\"gzip\")\n",
    "\n",
    "fname = \"url_independent_scores.csv.gzip\"\n",
    "url_export = urls[[\"url\", \"accuracy\", \"transparency\"]].copy()\n",
    "url_export = url_export.drop_duplicates().dropna(subset=[\"url\"])\n",
    "url_export.to_csv(join(dst, fname), index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854407a9-c578-4442-a0de-b671232aaa3a",
   "metadata": {},
   "source": [
    "# Create a tweet data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58b04781-9dad-4f95-bcbf-67ae7fedee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the current \"url\" data frame contains one row per URL, i.e. the same\n",
    "# tweet can be present more than once. To calculate the share of tweets with\n",
    "# unreliable information, we first calculate the mean NewsGuard score (and \n",
    "# mean accuracy and transparency) per tweet by averaging over all scores \n",
    "# of URLs that are present in a given tweet and then assigning \"fishy\" and\n",
    "# \"unreliable\" labels on the tweet level\n",
    "\n",
    "# columns that are defined on the tweet level\n",
    "#tweet_cols = [\"id\", \"author_id\", \"created_at\", \"retweeted\", \"quoted\", \"reply\",\n",
    "#              \"has_url\", \"handle\", \"name\", \"party\", \"tweet_length\"] + \\\n",
    "#             [\"avg_belief_score\", \"avg_truth_score\"] + \\\n",
    "#             [\"avg_belief_score_word2vec\", \"avg_truth_score_word2vec\"] + \\\n",
    "#             [\"avg_belief_score_fasttext\", \"avg_truth_score_fasttext\"] + \\\n",
    "#             [f\"avg_belief_score_{i}\" for i in range(100)] + \\\n",
    "#             [f\"avg_truth_score_{i}\" for i in range(100)]\n",
    "\n",
    "# note: use above columns if you run the script including the dictionary \n",
    "# robustness data\n",
    "tweet_cols = [\"id\", \"author_id\", \"created_at\", \"retweeted\", \"quoted\", \"reply\",\n",
    "              \"has_url\", \"handle\", \"name\", \"party\", \"tweet_length\"] + \\\n",
    "             [\"avg_belief_score\", \"avg_truth_score\"] + \\\n",
    "             [\"avg_belief_score_word2vec\", \"avg_truth_score_word2vec\"] + \\\n",
    "             [\"avg_belief_score_fasttext\", \"avg_truth_score_fasttext\"]\n",
    "tweets = urls[tweet_cols].drop_duplicates(subset=[\"id\"]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca01b4-9486-42e8-9b88-d3eb713989d9",
   "metadata": {},
   "source": [
    "## Add LIWC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11fe50d8-a937-4a04-aa14-786ef8ed7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_clean_LIWC.csv.gzip\"\n",
    "cols = [\"id\", \"Analytic\", \"Authentic\", \"moral\"]\n",
    "LIWC_scores = pd.read_csv(\n",
    "    join(src, fname), \n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    dtype={\"id\":str},\n",
    ")\n",
    "LIWC_scores = LIWC_scores.rename(columns={\n",
    "    \"Analytic\":\"LIWC_analytic\",\n",
    "    \"Authentic\":\"LIWC_authentic\",\n",
    "    \"moral\":\"LIWC_moral\",\n",
    "})\n",
    "tweets = pd.merge(tweets, LIWC_scores, how=\"left\", left_on=\"id\", right_on=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4debb2f7-9b4a-4025-bb18-768c57270e19",
   "metadata": {},
   "source": [
    "## Add VADER scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37021adf-778a-40c4-ae70-80df43e069c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_clean_VADER.csv.gzip\"\n",
    "VADER_scores = pd.read_csv(\n",
    "    join(src, fname), \n",
    "    compression=\"gzip\",\n",
    "    dtype={\"id\":str},\n",
    ")\n",
    "VADER_scores = VADER_scores.rename(columns={\n",
    "    \"neg\":\"VADER_neg\",\n",
    "    \"pos\":\"VADER_pos\",\n",
    "    \"neu\":\"VADER_neu\",\n",
    "    \"compound\":\"VADER_compound\"\n",
    "})\n",
    "tweets = pd.merge(tweets, VADER_scores, how=\"left\", left_on=\"id\", right_on=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a6213b-1870-4d10-b0eb-e29437d76fde",
   "metadata": {},
   "source": [
    "## Calculate average NewsGuard score and misinfo components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0fc3332-0793-444f-8764-ae7578b6b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores = urls[[\"id\", \"NG_score\", \"transparency\", \"accuracy\"]]\\\n",
    "    .groupby(\"id\")\\\n",
    "    .agg(\"mean\")\n",
    "\n",
    "average_scores[\"NG_unreliable\"] = np.nan\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"NG_score\"] < 60].index, \"NG_unreliable\"] = 1\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"NG_score\"] >= 60].index, \"NG_unreliable\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490d1c0-59ab-4342-922c-fce0572d5d5e",
   "metadata": {},
   "source": [
    "## Calculate average accuracy & transparency score and unreliable domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f70b5d3-ce28-4609-a8de-52feadeeaefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores[\"independent_unreliable\"] = np.nan\n",
    "# original definition: sources with transparency = 1 are unreliable\n",
    "# since transparency can have non-integer values after averaging, we decide\n",
    "# to label tweets with an average domain transparency value of links of\n",
    "# <= 1.5 as \"unreliable\", since that means that the majority of domains \n",
    "# linked to in the tweet are unreliable. If one domain with transparency 1\n",
    "# and one domain with transparency 2 are linked, the tweet is unreliable\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"transparency\"] <= 1.5].index, \"independent_unreliable\"] = 1\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"transparency\"] > 1.5].index, \"independent_unreliable\"] = 0\n",
    "# original defintion: sources with accuracy = 1 or 2 are unreliable\n",
    "# since accuracy can have non-integer values after averaging, we decide to\n",
    "# label tweets with an average domain accuracy value of links of <= 2.5 as\n",
    "# \"unreliable\", since that means that the majority of domains linked to in \n",
    "# the tweet are unreliable. If one domain with accuracy 2 and one domain \n",
    "# with accuracy 3 are linked, the tweet is unreliable.\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"accuracy\"] <= 2.5].index, \"independent_unreliable\"] = 1\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"accuracy\"] > 2.5].index, \"independent_unreliable\"] = 0\n",
    "\n",
    "tweets = pd.merge(tweets, average_scores, how=\"left\", left_on=\"id\", right_on=\"id\")\n",
    "del average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcce382-f6bf-4ad7-9b57-08ef20082a65",
   "metadata": {},
   "source": [
    "# Create a user data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc2de824-8f53-4876-abf6-01056ffdc0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = tweets[[\"author_id\", \"handle\", \"name\", \"party\", \"id\"]]\\\n",
    "    .groupby([\"author_id\", \"handle\", \"name\", \"party\"])\\\n",
    "    .agg(\"count\")\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"id\":\"N_tweets\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295d1f2-3815-4634-a192-dfa5166f6aa5",
   "metadata": {},
   "source": [
    "## Add account stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd97affd-963c-4ed5-9fcb-74a04207b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/users\"\n",
    "fname = \"US_politician_twitter_accounts_clean.csv\"\n",
    "cols = [\"followers_count\", \"following_count\", \"tweet_count\", \"created_at\", \n",
    "        \"author_id\"]\n",
    "account_stats = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    parse_dates=[\"created_at\"],\n",
    "    usecols=cols,\n",
    "    dtype={\"author_id\":str}\n",
    ")\n",
    "\n",
    "users = pd.merge(users, account_stats, how=\"left\", left_on=\"author_id\", right_on=\"author_id\")\n",
    "del account_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261401b6-eb61-4495-9bdb-a12570397fa0",
   "metadata": {},
   "source": [
    "## Add Congress information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e69ec38a-a3d1-4452-b740-ab537fbe7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/users/clean\"\n",
    "fname = \"congress-member-twitter-handles_114-118.csv\"\n",
    "congress_twitter_handles = pd.read_csv(join(src, fname))\n",
    "congress_twitter_handles = congress_twitter_handles\\\n",
    "    .sort_values(by=\"congress\", ascending=False)\\\n",
    "    .drop_duplicates(subset=\"handle\")\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "users = pd.merge(users, congress_twitter_handles, how=\"left\", left_on=\"handle\",\n",
    "                 right_on=\"handle\")\n",
    "del congress_twitter_handles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11974ba2-c6c1-42fa-9d99-bc1f1b949fd6",
   "metadata": {},
   "source": [
    "## Add share of untrustworthy domains (NewsGuard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a056d98f-6208-40d2-bb48-68e7861ac7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>NG_unreliable_sum</th>\n",
       "      <th>NG_unreliable_count</th>\n",
       "      <th>NG_unreliable_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002630999052865536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004891731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249</td>\n",
       "      <td>0.004016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id  NG_unreliable_sum  NG_unreliable_count  \\\n",
       "0  1002630999052865536                0.0                  100   \n",
       "1           1004891731                1.0                  249   \n",
       "\n",
       "   NG_unreliable_share  \n",
       "0             0.000000  \n",
       "1             0.004016  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"author_id\", \"NG_unreliable\"]\n",
    "unreliable_user_count = tweets[tweets[\"retweeted\"] == False][cols]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .agg([\"sum\", \"count\"])\n",
    "\n",
    "unreliable_user_count[\"NG_unreliable_share\"] = \\\n",
    "    unreliable_user_count[\"NG_unreliable\"][\"sum\"] / \\\n",
    "    unreliable_user_count[\"NG_unreliable\"][\"count\"]\n",
    "    \n",
    "# flatten the hierarchical indices\n",
    "unreliable_user_count = unreliable_user_count.reset_index()\n",
    "unreliable_user_count.columns = ['_'.join(col).strip(\"_\") \\\n",
    "                            for col in unreliable_user_count.columns.values]\n",
    "\n",
    "unreliable_user_count.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e070f70f-4543-4858-be3e-cf2bded68125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"NG_unreliable_share\", \"author_id\"]\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    unreliable_user_count[cols],\n",
    "    how=\"left\",\n",
    "    left_on=\"author_id\",\n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1daea-e29c-4328-b1c2-05f8e18f3a0b",
   "metadata": {},
   "source": [
    "## Add average NewsGuard score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7b53b46-f10e-4ef0-93e9-e86325f82211",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_NG_scores = tweets[tweets[\"retweeted\"] == False][[\"author_id\", \"NG_score\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"NG_score\":\"NG_score_mean\"})\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    average_NG_scores, \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6307c56-adfd-4d83-b111-9bb2e8461225",
   "metadata": {},
   "source": [
    "## Add average accuracy & transparency score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d17fb525-9a04-4192-8d16-7729d7041660",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy_transparency = tweets[tweets[\"retweeted\"] == False]\\\n",
    "    [[\"author_id\", \"accuracy\", \"transparency\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\n",
    "        \"accuracy\":\"accuracy_mean\",\n",
    "        \"transparency\":\"transparency_mean\"\n",
    "    })\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    average_accuracy_transparency, \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a4007-d097-44f5-a790-14bc31711dec",
   "metadata": {},
   "source": [
    "## Add share of unstrustworthy domains (independent list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40b07a89-36ca-4677-a73b-e853a1a20029",
   "metadata": {},
   "outputs": [],
   "source": [
    "unreliable_user_count = tweets[tweets[\"retweeted\"] == False]\\\n",
    "    [[\"author_id\", \"independent_unreliable\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .agg([\"sum\", \"count\"])\n",
    "\n",
    "unreliable_user_count[\"independent_unreliable_share\"] = \\\n",
    "    unreliable_user_count[\"independent_unreliable\"][\"sum\"] / \\\n",
    "    unreliable_user_count[\"independent_unreliable\"][\"count\"]\n",
    "    \n",
    "# flatten the hierarchical indices\n",
    "unreliable_user_count = unreliable_user_count.reset_index()\n",
    "unreliable_user_count.columns = ['_'.join(col).strip(\"_\") \\\n",
    "                            for col in unreliable_user_count.columns.values]\n",
    "\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    unreliable_user_count[[\"author_id\", \"independent_unreliable_share\"]],\n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "del unreliable_user_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20835b75-393f-43b7-a90d-1052d64f34e8",
   "metadata": {},
   "source": [
    "## Add average belief-speaking and truth-seeking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11c755fd-f871-4c72-9143-70f9c48bb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "honesty_tweets_score = tweets[tweets[\"retweeted\"] == False]\\\n",
    "    [[\"author_id\", \"avg_belief_score\", \"avg_truth_score\", \"created_at\"]]\\\n",
    "    .dropna(subset=[\"avg_belief_score\", \"avg_truth_score\"])\\\n",
    "    .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb06c889-9244-4d11-871d-19fdf897b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all honesty component tweets\n",
    "honesty_score_average = honesty_tweets_score\\\n",
    "    [[\"author_id\", \"avg_belief_score\", \"avg_truth_score\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\n",
    "\n",
    "honesty_score_average = honesty_score_average.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe8cfb14-8b77-451c-87ee-0334ed4a0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "honesty_tweets_score = honesty_tweets_score.set_index(\"created_at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a38b5189-4dc6-4b77-8eee-459adee64e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only first 4 years\n",
    "honesty_score_average_first = honesty_tweets_score[honesty_tweets_score.index.year <= 2013]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\n",
    "\n",
    "honesty_score_average_first = honesty_score_average_first.reset_index()\n",
    "cols = [\"avg_belief_score\", \"avg_truth_score\"]\n",
    "honesty_score_average_first = honesty_score_average_first\\\n",
    "    .rename(columns={col:col + \"_2010_to_2013\" for col in cols}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0e16e6d-4285-4467-af72-725c68fa1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only last 4 years\n",
    "honesty_score_average_last = honesty_tweets_score[honesty_tweets_score.index.year >= 2019]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\n",
    "honesty_score_average_last = honesty_score_average_last.reset_index()\n",
    "cols = [\"avg_belief_score\", \"avg_truth_score\"]\n",
    "honesty_score_average_last = honesty_score_average_last\\\n",
    "    .rename(columns={col:col + \"_2019_to_2022\" for col in cols}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a512ab21-cf2c-4ed1-9c59-7fae1e05ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.merge(honesty_score_average[[\"author_id\", \"avg_belief_score\", \n",
    "                    \"avg_truth_score\"]], how=\"left\", left_on=\"author_id\", \n",
    "                    right_on=\"author_id\")\n",
    "del honesty_score_average\n",
    "\n",
    "users = users.merge(\n",
    "    honesty_score_average_first,\n",
    "    how=\"left\",\n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "del honesty_score_average_first\n",
    "\n",
    "users = users.merge(\n",
    "    honesty_score_average_last,\n",
    "    how=\"left\",\n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "del honesty_score_average_last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ebb33-9474-4a43-9c1a-92a1d10c950f",
   "metadata": {},
   "source": [
    "## Add average LIWC and VADER scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d48e23f5-70d8-4dd8-ac44-f69c5d1a83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['LIWC_analytic', 'LIWC_authentic', 'LIWC_moral',\n",
    "        'VADER_neg', 'VADER_pos', 'VADER_neu', 'VADER_compound']\n",
    "average_scores = tweets\\\n",
    "    [[\"author_id\"] + cols]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\\\n",
    "    .reset_index()\n",
    "score_map = {score:f\"{score}_mean\" for score in cols}\n",
    "average_scores = average_scores.rename(columns=score_map)\n",
    "\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    average_scores, \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d5df9-59f6-42d8-85e7-8c3702603805",
   "metadata": {},
   "source": [
    "## Add ideology scores and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e77d54eb-c6c5-4ca6-9980-9dec16b0b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/utilities\"\n",
    "fname = \"govtrack-stats-{}-{}-ideology.csv\"\n",
    "ideology_scores = pd.DataFrame()\n",
    "# note: scorecards for 2021 are missing in govtrack\n",
    "for year in list(range(2013, 2021)) + [2022]:\n",
    "    for chamber in [\"house\", \"senate\"]:\n",
    "        tmp = pd.read_csv(join(src, \"ideology_scores\",\n",
    "                               fname.format(year, chamber)))\n",
    "        tmp[\"year\"] = year\n",
    "        tmp[\"name\"] = tmp[\"name\"].apply(lambda x: x.replace(\"b'\", \"\"))\n",
    "        tmp[\"name\"] = tmp[\"name\"].apply(lambda x: x.replace(\"'\", \"\").lower())\n",
    "        ideology_scores = pd.concat([ideology_scores, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4225918e-470e-4139-a980-d1c97587e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match politician Twitter account names to govtrack politician names\n",
    "\n",
    "# a single politician can have at maximum 9 entries for 9 different years\n",
    "# 2013 to 2020 plus 2022\n",
    "counts = ideology_scores[\"name\"].value_counts()\n",
    "unique_names = list(counts[counts <= 8].index)\n",
    "\n",
    "unique_scores = ideology_scores[ideology_scores[\"name\"].isin(unique_names)]\\\n",
    "    .sort_values(by=\"year\", ascending=False)\\\n",
    "    .drop_duplicates(subset=[\"name\"])\\\n",
    "    .set_index(\"name\")\n",
    "unique_names = list(set(unique_scores.index))\n",
    "\n",
    "def match_score(account_name):\n",
    "    '''Matches govtrack politician names to Twitter account names.'''\n",
    "    if account_name == account_name:\n",
    "        account_name = set(account_name.lower().split(\" \"))\n",
    "        for name in unique_names:\n",
    "            # hard matching: if the govtrack name string is completely included\n",
    "            # in the Twitter account name string, record a match\n",
    "            if name in account_name:\n",
    "                return unique_scores.loc[name][\"id\"]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "users[\"ideology_score_id\"] = users[\"name\"].apply(match_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28e6f597-1240-4040-a814-8fab957ba0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hand-matched missing scores\n",
    "src = \"../../data/utilities\"\n",
    "fname = \"missing_govtrack_ideology_scores.csv\"\n",
    "missing_scores = pd.read_csv(join(src, fname))\n",
    "missing_scores = {row[\"handle\"]:row[\"ideology_score_id\"] \\\n",
    "                  for i, row in missing_scores.iterrows()}\n",
    "\n",
    "# index on the handle since this seems to be the most consistent index between\n",
    "# the two datasets\n",
    "users = users.set_index(\"handle\")\n",
    "for handle, score_id in missing_scores.items():\n",
    "    if handle in users.index:\n",
    "        users.loc[handle, \"ideology_score_id\"] = score_id\n",
    "users = users.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "970b5966-4348-4e4a-b270-9f7b87177fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for many accounts, there is more than one ideology score since they were \n",
    "# active over many years. We calculate the mean, std and count of the ideology\n",
    "# score for each user and add this information to the user_df\n",
    "ideology_scores_agg = ideology_scores[[\"id\", \"ideology\"]]\\\n",
    "    .groupby(\"id\")\\\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "ideology_scores_agg = ideology_scores_agg.reset_index()\n",
    "ideology_scores_agg.columns = ['_'.join(col).strip(\"_\") \\\n",
    "                            for col in ideology_scores_agg.columns.values]\n",
    "\n",
    "# add a state for each politician\n",
    "states = ideology_scores[[\"id\", \"state\"]].drop_duplicates()\n",
    "ideology_scores_agg = ideology_scores_agg.merge(states, how=\"left\",\n",
    "                left_on=\"id\", right_on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2805c43d-81d9-4776-aac7-76b4e73be80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.merge(ideology_scores_agg, how=\"left\", \n",
    "                      left_on=\"ideology_score_id\", right_on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2298c786-0e4f-4b12-b05a-e1099a420f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hand-matched missing states\n",
    "missing_states = pd.read_csv(\n",
    "    join(src, \"missing_states.csv\"),\n",
    "    usecols=[\"handle\", \"state\"]\n",
    ").set_index(\"handle\")\n",
    "\n",
    "users = users.set_index(\"handle\")\n",
    "users.loc[missing_states.index, \"state\"] = missing_states\n",
    "users = users.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fdac378-bf1d-49a2-a9f2-cc8749310872",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ideology_scores\n",
    "del ideology_scores_agg\n",
    "del states\n",
    "del missing_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e52b7e7-4487-4e38-a701-e572c43930dc",
   "metadata": {},
   "source": [
    "## Add Politifact scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc203c1d-6d46-413d-a1b5-2fb3a1e88b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/utilities\"\n",
    "fname = \"misinfo_score_politifact.csv\"\n",
    "pf_scores = pd.read_csv(join(src, fname), \n",
    "        usecols=[\"pf_score\", \"elite_account\"])\\\n",
    "    .rename(columns={\"elite_account\":\"handle\"})\n",
    "\n",
    "users = pd.merge(users, pf_scores, how=\"left\", left_on=\"handle\", right_on=\"handle\")\n",
    "del pf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c0265-fecb-4048-bd50-802e4eeb3177",
   "metadata": {},
   "source": [
    "# Data exports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce73d2-f5f7-4a27-b46b-7c11abcc2f82",
   "metadata": {},
   "source": [
    "## URL, tweet and user data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ace989-47ce-4966-9ec8-21da8180e4ae",
   "metadata": {},
   "source": [
    "**Note**: if you are running this code including the data for the dictionary robustness ananlysis, saving the files takes a while because they are pretty large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f0fcc5e-1982-4323-801c-6614c8250d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38c29338-6b28-41e7-b93c-c2ae005d9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL data frame\n",
    "fname = \"US_politician_URLs_2010-11-06_to_2022-12-31.csv.gzip\"\n",
    "urls = urls[urls[\"has_url\"] == True]\n",
    "urls = urls.drop(columns=[\"url\", \"handle\", \"name\", \"has_url\"])\n",
    "urls.to_csv(join(dst, \"urls\", fname), index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d12e8d4-6651-4dc0-988a-fca8d50be901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user data frame\n",
    "fname = \"users.csv\"\n",
    "users = users.drop(columns=[\"ideology_score_id\", \"id\"])\n",
    "users.to_csv(join(dst, \"users\", fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2e6b858-14f8-40d0-bdc4-7ad842836fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet data frame\n",
    "fname = \"US_politician_tweets_2010-11-06_to_2022-12-31.csv.gzip\"\n",
    "tweets = tweets.drop(columns=[\"handle\", \"name\"])\n",
    "tweets.to_csv(join(dst, \"tweets\", fname), index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a69d5c-fc6a-43f1-ad6b-d7d8dad5ba10",
   "metadata": {},
   "source": [
    "## Data for linear mixed effects modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bffefdbc-708d-419f-b1d2-aa2bca58dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3dddd13-c955-4400-bd1a-482abdd43a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"US_politician_tweets_2010-11-06_to_2022-12-31.csv.gzip\"\n",
    "cols = [\n",
    "    \"author_id\", # data grouping: independent random variable\n",
    "    \"party\", # characteristic of author: independent fixed variable\n",
    "    \"avg_belief_score\", # fixed variable\n",
    "    \"avg_truth_score\", # fixed variable\n",
    "    \"NG_score\", # dependent variable\n",
    "    \"accuracy\", # dependent variable\n",
    "    \"transparency\", # dependent variable\n",
    "]\n",
    "tweets = pd.read_csv(\n",
    "    join(src, \"tweets\", fname),\n",
    "    compression=\"gzip\", \n",
    "    usecols=cols, \n",
    "    dtype={\"author_id\":str},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c950f2c4-7dc9-41ae-8f50-63cc062b16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"users.csv\"\n",
    "cols = [\"author_id\", \"ideology_mean\"]\n",
    "users = pd.read_csv(join(src, \"users\", fname), dtype={\"author_id\":str}, usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f049be3-2d6e-4d26-92d3-7c5b2953cb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3876333"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets[tweets[\"party\"].isin([\"Democrat\", \"Republican\"])] # remove independents\n",
    "tweets = tweets.dropna(subset=[\"avg_belief_score\", \"avg_truth_score\"]) # remove tweets without NG, belief or truth score\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e430679d-0658-4067-a0f4-b29781eecdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3876332"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out authors with only a single tweet\n",
    "tweet_counts = tweets[\"author_id\"]\\\n",
    "    .value_counts()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"index\":\"author_id\", \"author_id\":\"count\"})\n",
    "\n",
    "tweets = tweets[tweets[\"author_id\"].isin(tweet_counts[tweet_counts[\"count\"] > 1][\"author_id\"])]\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b4b94e0-494c-42b4-abf0-13cd5861d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.merge(\n",
    "    tweets,\n",
    "    users,\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "052e9fb5-4725-4581-8f32-309ac68b8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center similarity scores\n",
    "tweets[\"belief\"] = tweets[\"avg_belief_score\"]# - tweets[\"avg_belief_score\"].mean()\n",
    "tweets[\"truth\"] = tweets[\"avg_truth_score\"]# - tweets[\"avg_truth_score\"].mean()\n",
    "# normalize trustworthiness scores by maximum scale value\n",
    "tweets[\"NG\"] = tweets[\"NG_score\"] / 100\n",
    "tweets[\"accuracy\"] = tweets[\"accuracy\"] / 5\n",
    "tweets[\"transparency\"] = tweets[\"transparency\"] / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23745734-9a7d-4741-a5bc-9288a93e96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"author_id\", \"party\", \"belief\", \"truth\"]\n",
    "# only tweets that have a NewsGuard score\n",
    "tweets_NG = tweets[cols + [\"NG\"]].dropna()\n",
    "# only tweets that have an accuracy/transparency score\n",
    "tweets_independent = tweets[cols + [\"accuracy\", \"transparency\"]].dropna()\n",
    "\n",
    "dst = \"../../data/tweets\"\n",
    "tweets_NG.to_csv(join(dst, \"tweets_for_lme_modelling_NG.csv\"), index=False)\n",
    "tweets_independent.to_csv(join(dst, \"tweets_for_lme_modelling_independent.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec0ae3e-10f4-43f5-9120-55954c25255f",
   "metadata": {},
   "source": [
    "## Data for linear mixed effects modelling other embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dbfa8951-7dc8-40bd-bbcd-b22ddc94a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a98bd4fc-84bd-4c3e-a7d2-7639944b36a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"US_politician_tweets_2010-11-06_to_2022-12-31.csv.gzip\"\n",
    "cols = [\n",
    "    \"author_id\", # data grouping: independent random variable\n",
    "    \"party\", # characteristic of author: independent fixed variable\n",
    "    \"avg_belief_score_word2vec\", # fixed variable\n",
    "    \"avg_truth_score_word2vec\", # fixed variable\n",
    "    \"avg_belief_score_fasttext\", # fixed variable\n",
    "    \"avg_truth_score_fasttext\", # fixed variable\n",
    "    \"NG_score\", # dependent variable\n",
    "]\n",
    "tweets = pd.read_csv(\n",
    "    join(src, \"tweets\", fname),\n",
    "    compression=\"gzip\", \n",
    "    usecols=cols, \n",
    "    dtype={\"author_id\":str},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a136a5aa-bc08-4040-824f-4d0330b710dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3876333"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets[tweets[\"party\"].isin([\"Democrat\", \"Republican\"])] # remove independents\n",
    "tweets = tweets.dropna(subset=[\"avg_belief_score_word2vec\", \"avg_truth_score_word2vec\",\n",
    "                               \"avg_belief_score_fasttext\", \"avg_truth_score_fasttext\"]) # remove tweets without NG, belief or truth score\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e92a8728-6c76-4d13-a35d-15ad799221f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3876332"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out authors with only a single tweet\n",
    "tweet_counts = tweets[\"author_id\"]\\\n",
    "    .value_counts()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"index\":\"author_id\", \"author_id\":\"count\"})\n",
    "\n",
    "tweets = tweets[tweets[\"author_id\"].isin(tweet_counts[tweet_counts[\"count\"] > 1][\"author_id\"])]\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "053d75a4-fd73-437a-bd34-2f60cb738240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up column names\n",
    "tweets = tweets.rename(columns={\n",
    "    \"avg_belief_score_word2vec\":\"belief_word2vec\",\n",
    "    \"avg_belief_score_fasttext\":\"belief_fasttext\",\n",
    "    \"avg_truth_score_word2vec\":\"truth_word2vec\",\n",
    "    \"avg_truth_score_fasttext\":\"truth_fasttext\"\n",
    "})\n",
    "\n",
    "# normalize trustworthiness scores by maximum scale value\n",
    "tweets[\"NG\"] = tweets[\"NG_score\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aeff87e2-5d34-4282-953c-a05f5682674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"author_id\", \"party\", \"belief_word2vec\", \"truth_word2vec\", \"belief_fasttext\", \"truth_fasttext\"]\n",
    "# only tweets that have a NewsGuard score\n",
    "tweets = tweets[cols + [\"NG\"]].dropna()\n",
    "\n",
    "dst = \"../../data/tweets\"\n",
    "tweets.to_csv(join(dst, \"tweets_for_lme_modelling_other_embeddings.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79faab80-ddda-4055-9ff5-f469bbadab81",
   "metadata": {},
   "source": [
    "## Data for topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d156dcf-399b-47b3-90b1-49f189a4951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the tweet data\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_clean.csv.gzip\"\n",
    "cols = [\"id\", \"author_id\", \"text\"]\n",
    "tweets = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    dtype={\"id\":str, \"author_id\":str}\n",
    ")\n",
    "tweets[\"id\"] = tweets[\"id\"].str.replace('\"', '')\n",
    "tweets[\"author_id\"] = tweets[\"author_id\"].str.replace('\"', '')\n",
    "\n",
    "# read the honesty scores\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_honesty_component_scores_glove.csv.gzip\"\n",
    "cols = [\"id\", \"avg_belief_score\", \"avg_truth_score\"]\n",
    "honesty_scores = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    dtype={\"id\":str}\n",
    ")\n",
    "\n",
    "# add honesty component scores\n",
    "tweets = pd.merge(\n",
    "    tweets,\n",
    "    honesty_scores,\n",
    "    how=\"left\",\n",
    "    left_on=\"id\",\n",
    "    right_on=\"id\"\n",
    ")\n",
    "\n",
    "# add party information\n",
    "tweets = pd.merge(\n",
    "    tweets,\n",
    "    users[[\"author_id\", \"party\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"author_id\",\n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "\n",
    "# drop all tweets without party and honesty score information (retweets and\n",
    "# tweets with too short text that don't have honesty scores)\n",
    "tweets = tweets.dropna()\n",
    "\n",
    "# drop all tweets that are not from Democrats or Republicans\n",
    "tweets = tweets[tweets[\"party\"].isin([\"Democrat\", \"Republican\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1526c543-c5a8-42f7-8e64-e7c681759c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 20 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# lemmatize text - note: this takes a while\n",
    "from pandarallel import pandarallel\n",
    "import spacy\n",
    "pandarallel.initialize(nb_workers=20)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "tweets[\"lemmatized\"] = tweets['text']\\\n",
    "    .parallel_apply(lambda x: \" \".join([y.lemma_ for y in nlp(x)]))\n",
    "\n",
    "tweets['lemmatized'] = tweets['lemmatized'].str.replace(r'\\s+|\\\\n', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201ac46-9c07-41f3-a3f2-ce350780ef31",
   "metadata": {},
   "source": [
    "## Calculate quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f1c570bd-25ad-464d-8ca4-dd8bca6ff0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify tweets that are in the top belief-speaking similarity and \n",
    "# truth-seeking similarity quantiles and assign them to the \"belief\" and \"truth\"\n",
    "# categories. If a tweet is in both top quantiles, assign them to the category\n",
    "# with the higher similarity\n",
    "belief_quant = tweets[\"avg_belief_score\"].quantile(0.8)\n",
    "truth_quant = tweets[\"avg_truth_score\"].quantile(0.8)\n",
    "tweets[\"belief\"] = 0\n",
    "tweets[\"truth\"] = 0\n",
    "\n",
    "# assign categories based on quantiles\n",
    "tweets.loc[tweets[tweets[\"avg_belief_score\"] >= belief_quant].index, \"belief\"] = 1\n",
    "tweets.loc[tweets[tweets[\"avg_truth_score\"] >= truth_quant].index, \"truth\"] = 1\n",
    "\n",
    "# tweets that are in both categories\n",
    "tweets.loc[tweets[\n",
    "    (tweets[\"belief\"] == 1) & (tweets[\"truth\"] == 1) & \\\n",
    "    (tweets[\"avg_belief_score\"] > tweets[\"avg_truth_score\"])].index, \"truth\"] = 0\n",
    "tweets.loc[tweets[\n",
    "    (tweets[\"belief\"] == 1) & (tweets[\"truth\"] == 1) & \\\n",
    "    (tweets[\"avg_truth_score\"] > tweets[\"avg_belief_score\"])].index, \"belief\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b19ce406-8495-48e1-8bd2-754dd0a57b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign tweets to honesty component X party categories\n",
    "tweets[\"classes_quant\"] = np.nan\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Democrat\") & (tweets[\"belief\"] == 1)].index, \"classes_quant\"] = \"db\"\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Democrat\") & (tweets[\"truth\"] == 1)].index, \"classes_quant\"] = \"dt\"\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Republican\") & (tweets[\"belief\"] == 1)].index, \"classes_quant\"] = \"rb\"\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Republican\") & (tweets[\"truth\"] == 1)].index, \"classes_quant\"] = \"rt\"\n",
    "\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Democrat\") & (tweets[\"belief\"] == 0) & (tweets[\"truth\"] == 0)].index, \"classes_quant\"] = \"dn\"\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Republican\") & (tweets[\"belief\"] == 0) & (tweets[\"truth\"] == 0)].index, \"classes_quant\"] = \"rn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e6574eb-2cd2-40cd-87fd-4a62cb2c728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_lemma.csv.gzip\"\n",
    "cols = [\"id\", \"author_id\", \"lemmatized\", \"party\", \"avg_belief_score\",\n",
    "        \"avg_truth_score\", \"classes_quant\"]\n",
    "tweets[cols].to_csv(\n",
    "    join(dst, fname),\n",
    "    compression=\"gzip\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d5b4620-422b-490d-9666-349e025547a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-12-31_lemma.csv.gzip\"\n",
    "tweets = pd.read_csv(\n",
    "    join(dst, fname),\n",
    "    compression=\"gzip\",\n",
    "    dtype={\"id\":str, \"author_id\":str},\n",
    "    usecols=[\"id\", \"author_id\", \"lemmatized\", \"party\", \"classes_quant\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c14cfb-a216-4015-804b-d95d5407cc86",
   "metadata": {},
   "source": [
    "# Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f33378e-4ee1-48c9-8278-24e5980eb6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_corpus_clean.csv.gzip\t  remaining_urls.csv.gzip\n",
      "article_corpus_combined.csv.gzip  url_independent_scores.csv.gzip\n",
      "article_corpus_raw_0.csv.gzip\t  url_list_for_article_scraping.csv.gzip\n",
      "article_corpus_raw.csv.gzip\t  url_NG_scores.csv.gzip\n",
      "raw_scrape_020323.csv\n"
     ]
    }
   ],
   "source": [
    "! ls ../../data/articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "230f3ffa-3ae1-4db7-905f-34136738b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../../data/articles/article_corpus_clean.csv.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0164f247-ac3e-4f39-b792-1abe1215b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../../data/articles/raw_scrape_020323.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd4474f7-b536-4a2b-a713-1a51b6cedfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1[[\"url\", \"link_text\"]], df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b34f71e8-5798-4dee-8faf-b393f04f648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"url\", \"link_text\"]].to_csv(\"../../data/articles/article_corpus_combined.csv.gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0819edd-3bad-4699-b622-d22ff2dd2e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "611511"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e10c828-eb7a-471d-b0ea-75aadbba05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67ebe861-ec62-4926-b25b-85643bdf49be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610057"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4926c74f-7d9b-407f-964f-72243a469f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"url_list_for_article_scraping.csv.gzip\"\n",
    "urls = pd.read_csv(join(dst, \"articles\", fname), compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d83ad71b-ce9a-4505-999b-6e3d3ee82966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, urls, how=\"left\", left_on=\"url\", right_on=\"url\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd0aa3bd-d424-4123-b863-0bdf5b4a8746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428815"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a47b7ec-bc60-4cd1-996c-372c355d7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"link_text\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "359e2019-7880-48c2-a86a-f3cbf5fd0b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428815"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6ac68-4122-4da9-85b1-593ab782f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"unfortunately our website is currently unavailable in most European countries due to GDPR rules\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5fd409f-67c2-4b61-8ed0-c96d72840082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>https://twitter.com/RepBillJohnson/status/1608...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>https://twitter.com/RepBillJohnson/status/1608...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>https://twitter.com/RepBillJohnson/status/1608...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>https://twitter.com/RepBillJohnson/status/1608...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>https://twitter.com/RepBillJohnson/status/1606...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885053</th>\n",
       "      <td>thehill.com</td>\n",
       "      <td>https://thehill.com/blogs/congress-blog/econom...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885054</th>\n",
       "      <td>blog.chron.com</td>\n",
       "      <td>http://blog.chron.com/txpotomac/2012/05/the-be...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885055</th>\n",
       "      <td>cuellar.house.gov</td>\n",
       "      <td>https://cuellar.house.gov/news/rss.aspx</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885056</th>\n",
       "      <td>cuellar.house.gov</td>\n",
       "      <td>https://cuellar.house.gov/news/documentsingle....</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885057</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>https://twitter.com/RepCuellar/status/19019915...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2885058 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    domain                                                url  \\\n",
       "0              twitter.com  https://twitter.com/RepBillJohnson/status/1608...   \n",
       "1              twitter.com  https://twitter.com/RepBillJohnson/status/1608...   \n",
       "2              twitter.com  https://twitter.com/RepBillJohnson/status/1608...   \n",
       "3              twitter.com  https://twitter.com/RepBillJohnson/status/1608...   \n",
       "4              twitter.com  https://twitter.com/RepBillJohnson/status/1606...   \n",
       "...                    ...                                                ...   \n",
       "2885053        thehill.com  https://thehill.com/blogs/congress-blog/econom...   \n",
       "2885054     blog.chron.com  http://blog.chron.com/txpotomac/2012/05/the-be...   \n",
       "2885055  cuellar.house.gov            https://cuellar.house.gov/news/rss.aspx   \n",
       "2885056  cuellar.house.gov  https://cuellar.house.gov/news/documentsingle....   \n",
       "2885057        twitter.com  https://twitter.com/RepCuellar/status/19019915...   \n",
       "\n",
       "              party  \n",
       "0        Republican  \n",
       "1        Republican  \n",
       "2        Republican  \n",
       "3        Republican  \n",
       "4        Republican  \n",
       "...             ...  \n",
       "2885053    Democrat  \n",
       "2885054    Democrat  \n",
       "2885055    Democrat  \n",
       "2885056    Democrat  \n",
       "2885057    Democrat  \n",
       "\n",
       "[2885058 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d049b52-2d78-4cfe-845f-f2cd1e0a7a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/articles/article_corpus_clean.csv.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e04d1234-7ab5-4e9f-aa59-be5aaaf85684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>link_text</th>\n",
       "      <th>remove</th>\n",
       "      <th>wc</th>\n",
       "      <th>party</th>\n",
       "      <th>NG_score</th>\n",
       "      <th>fishy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.washingtonpost.com/politics/2018/1...</td>\n",
       "      <td>\\n\\nDays before the midterm elections, Preside...</td>\n",
       "      <td>keep</td>\n",
       "      <td>775</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>100.0</td>\n",
       "      <td>non_fishy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://apnews.com/eb82c8597cef4c95a473e525402...</td>\n",
       "      <td>Residents look at a home damaged by a magnitud...</td>\n",
       "      <td>keep</td>\n",
       "      <td>715</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>95.0</td>\n",
       "      <td>non_fishy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.usatoday.com/story/news/nation/201...</td>\n",
       "      <td>Federal judge blocks Trump from deporting hund...</td>\n",
       "      <td>keep</td>\n",
       "      <td>1116</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>100.0</td>\n",
       "      <td>non_fishy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.cnn.com/2018/10/03/politics/senate...</td>\n",
       "      <td>Washington (CNN) The Senate on Wednesday passe...</td>\n",
       "      <td>keep</td>\n",
       "      <td>144</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>80.0</td>\n",
       "      <td>non_fishy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.usatoday.com/story/travel/flights/...</td>\n",
       "      <td>Senate approves bill that would regulate airli...</td>\n",
       "      <td>keep</td>\n",
       "      <td>506</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>100.0</td>\n",
       "      <td>non_fishy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.washingtonpost.com/politics/2018/1...   \n",
       "1  https://apnews.com/eb82c8597cef4c95a473e525402...   \n",
       "2  https://www.usatoday.com/story/news/nation/201...   \n",
       "3  https://www.cnn.com/2018/10/03/politics/senate...   \n",
       "4  https://www.usatoday.com/story/travel/flights/...   \n",
       "\n",
       "                                           link_text remove    wc     party  \\\n",
       "0  \\n\\nDays before the midterm elections, Preside...   keep   775  Democrat   \n",
       "1  Residents look at a home damaged by a magnitud...   keep   715  Democrat   \n",
       "2  Federal judge blocks Trump from deporting hund...   keep  1116  Democrat   \n",
       "3  Washington (CNN) The Senate on Wednesday passe...   keep   144  Democrat   \n",
       "4  Senate approves bill that would regulate airli...   keep   506  Democrat   \n",
       "\n",
       "   NG_score      fishy  \n",
       "0     100.0  non_fishy  \n",
       "1      95.0  non_fishy  \n",
       "2     100.0  non_fishy  \n",
       "3      80.0  non_fishy  \n",
       "4     100.0  non_fishy  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0399bcd8-a217-47df-987c-1a158f6ef2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354335"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
