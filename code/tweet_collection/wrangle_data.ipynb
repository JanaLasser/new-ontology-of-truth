{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316acf0-df86-4849-bfce-ae80cceac5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Jana Lasser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d70086-b0cd-471d-867d-21e782483b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139da757-f9f3-4839-b4e8-224adf5dafd7",
   "metadata": {},
   "source": [
    "# Create a URL data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bc1b3-3813-489c-8aa9-266ddf21b8fe",
   "metadata": {},
   "source": [
    "## Expand URL lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0d47cd12-d37e-48b2-9c2a-762a6cedc62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned timeline-data\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_clean.csv.gzip\"\n",
    "cols = [\"id\", \"author_id\", \"created_at\", \"expanded_urls\",\n",
    "        \"retweeted\", \"quoted\", \"reply\"]\n",
    "tweets = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols)\n",
    "tweets = tweets.drop_duplicates(subset=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ffcd134-eaad-4cc9-b662-6f0067f2d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the URL lists\n",
    "tweets[\"expanded_urls\"] = tweets[\"expanded_urls\"].fillna(\"[]\")\n",
    "tweets[\"expanded_urls\"] = tweets[\"expanded_urls\"].apply(lambda x: eval(x))\n",
    "tweets[\"has_url\"] = tweets[\"expanded_urls\"].apply(lambda x: len(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "696f9f53-bd91-4e8c-adb7-592e7199f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"N_urls\"] = tweets[\"expanded_urls\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb66c73-f676-4875-ad0c-2a46a99cc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand only entries with multiple URLs\n",
    "multiple_urls = tweets[tweets[\"N_urls\"] > 1]\n",
    "expanded_urls = pd.DataFrame()\n",
    "for idx, entry in multiple_urls.iterrows():\n",
    "    row = {key:val for key, val in entry.items()}\n",
    "    expanded_urls = pd.concat([expanded_urls, pd.DataFrame(row)])\n",
    "    \n",
    "expanded_urls = expanded_urls.set_index(\"id\")\n",
    "urls = tweets.copy()\n",
    "urls = urls.set_index(\"id\")\n",
    "# drop entries with mutiple URLs\n",
    "urls = urls.drop(multiple_urls[\"id\"].values)\n",
    "# add expanded entries with one line for each URL\n",
    "urls = pd.concat([urls, expanded_urls])\n",
    "urls = urls.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03594ce-f9b9-43f3-9b95-fa5ecf9dfac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910bb11-3cf4-4fec-a136-795b73229929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, some URLs are stored as singular entries of a list, and some as string.\n",
    "# empty entries are stored as empty list. Below we streamline URL entries such\n",
    "# that every entry is a single string\n",
    "def extract_URL_from_list(entry):\n",
    "    if len(entry) == 0:\n",
    "        return np.nan\n",
    "    elif len(entry) == 1:\n",
    "        return entry[0]\n",
    "    else:\n",
    "        return entry\n",
    "    \n",
    "urls[\"expanded_urls\"] = urls[\"expanded_urls\"].apply(extract_URL_from_list)\n",
    "urls = urls.drop(columns=[\"urls\", \"entities.urls\"])\n",
    "urls = urls.rename(columns={\"expanded_urls\":\"url\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a37e86-396c-4706-ac02-0b3f4f2c5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some tweets contain the same URL twice. We drop these\n",
    "N = len(urls)\n",
    "urls = urls.drop_duplicates(subset=[\"id\", \"url\"])\n",
    "print(f\"dropped {N - len(urls)} duplicate URL entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5cb331-3aee-4fe9-b6ea-d8ec5b0d35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba76e8-09a0-4f2e-bd7c-198a30a14e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outcome\n",
    "dst = \"../../data/urls\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2021-03-16_clean_urls.csv.gzip\"\n",
    "urls.to_csv(join(dst, fname), compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9287984-bfed-41cd-b853-226df27367c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data frame with the expanded URLs\n",
    "src = \"../../data/urls\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2021-03-16_clean_urls.csv.gzip\"\n",
    "cols = [\"id\", \"author_id\", \"created_at\", \"url\", \"retweeted\",\n",
    "        \"quoted\", \"reply\", \"has_url\"]\n",
    "urls = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    parse_dates=[\"created_at\"],\n",
    "    dtype={\"author_id\":str, \"id\":str}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07371d18-7280-4dc1-9723-fc500507ec3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsrc = \"../../data/tweets\"\\nfname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_clean.csv.gzip\"\\ntweet_metrics = pd.read_csv(join(src, fname),\\n                 compression=\"gzip\",\\n                 usecols=[\"id\", \"retweet_count\",\\n                          \"reply_count\", \"like_count\", \"quote_count\"],\\n                dtype={\"id\":str})\\ntweet_metrics = tweet_metrics.drop_duplicates(subset=\"id\")\\n# merge the tweet metrics with the tweet data frame\\nurls = pd.merge(urls, tweet_metrics, how=\"left\", left_on=\"id\", right_on=\"id\")\\ndel tweet_metrics\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the public metrics information for the collected tweets\n",
    "# note: this is not needed for the analysis in this publication, but might be\n",
    "# handy for analyses of tweet engagement metrics\n",
    "'''\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_clean.csv.gzip\"\n",
    "tweet_metrics = pd.read_csv(join(src, fname),\n",
    "                 compression=\"gzip\",\n",
    "                 usecols=[\"id\", \"retweet_count\",\n",
    "                          \"reply_count\", \"like_count\", \"quote_count\"],\n",
    "                dtype={\"id\":str})\n",
    "tweet_metrics = tweet_metrics.drop_duplicates(subset=\"id\")\n",
    "# merge the tweet metrics with the tweet data frame\n",
    "urls = pd.merge(urls, tweet_metrics, how=\"left\", left_on=\"id\", right_on=\"id\")\n",
    "del tweet_metrics\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d582d2-3902-4505-b3f2-912132db85ba",
   "metadata": {},
   "source": [
    "## Add unraveled URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0a307d6-8c0f-4f81-943f-2224dde5809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of originally shortened URLs with their expansions to their true\n",
    "# destination\n",
    "src = \"../../data/urls\"\n",
    "fname = \"US_unraveled_urls.csv.xz\"\n",
    "unraveled_urls = pd.read_csv(join(src, fname), compression=\"xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99817340-0e3c-4ff3-bf3f-39e28d4c712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add URL information\n",
    "urls = pd.merge(urls, unraveled_urls, left_on=\"url\", right_on=\"url\", how=\"left\")\n",
    "\n",
    "# add indicator of whether the URL was originally shortened\n",
    "urls[\"shortened_url\"] = False\n",
    "urls.loc[urls[\"unraveled_url\"].dropna().index, \"shortened_url\"] = True\n",
    "\n",
    "# replace the shortened URL with the unraveled URL\n",
    "urls.loc[urls[\"unraveled_url\"].dropna().index, \"url\"] = \\\n",
    "    urls.loc[urls[\"unraveled_url\"].dropna().index, \"unraveled_url\"]\n",
    "urls = urls.drop(columns=[\"unraveled_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1eb618ca-2d99-4b12-b55d-34cba20edadf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found malformed URL https\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n"
     ]
    }
   ],
   "source": [
    "# extract the domain from the URL. Note: a few \"found malformed URL\" warnings\n",
    "# are acceptable\n",
    "def extract_domain(url):\n",
    "    '''Given an ULR, extracts the domain name in the form XXXXX.YY'''\n",
    "    if url != url:\n",
    "        return np.nan\n",
    "    # reformat entries that have the domain after a general name in parantheses\n",
    "    if url.find('(') > 0:\n",
    "        url = url.split('(')[-1]\n",
    "        url = url.strip(')')\n",
    "    # trailing \"/\" and spaces\n",
    "    url = url.strip('/').strip()\n",
    "    # transform all domains to lowercase\n",
    "    url = url.lower()\n",
    "    # remove any white spaces\n",
    "    url = url.replace(' ', '')\n",
    "    # if present: remove the protocol\n",
    "    if url.startswith((\"http\", \"https\")):\n",
    "        try:\n",
    "            url = url.split('//')[1]\n",
    "        except IndexError:\n",
    "            print(f\"found malformed URL {url}\")\n",
    "            return np.nan\n",
    "    # remove \"www.\" \n",
    "    url = url.replace('www.', '')\n",
    "    url = url.split(\"/\")[0]\n",
    "    return url\n",
    "\n",
    "urls[\"domain\"] = urls[\"url\"].apply(extract_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beecaea6-0097-46bd-81ba-447d54aedbe7",
   "metadata": {},
   "source": [
    "## Add NewsGuard nutrition scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bd17d-6a55-4776-bb34-082cf521baf6",
   "metadata": {},
   "source": [
    "Newsguard rating threshold to label a domain as \"unreliable\": 60 (see [description](https://www.newsguardtech.com/ratings/rating-process-criteria/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b883f36-4d22-4e78-ae0d-3b5efa10fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e27eb7a1-a3c0-4b14-8cd3-3b003a6d0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the nutrition labels\n",
    "src = \"../../data/utilities/\"\n",
    "fname = \"NewsGuard_labels.csv\"\n",
    "cols = [\"Domain\", \"Score\", \"Last Updated\"]\n",
    "NG_scores = pd.read_csv(join(src, fname), usecols=cols)\n",
    "# if more than one score exists for the same domain, keep the most recent one\n",
    "NG_scores = NG_scores.sort_values(by=[\"Domain\",\"Last Updated\"], ascending=False)\n",
    "NG_scores = NG_scores.drop_duplicates(subset=[\"Domain\"])\n",
    "NG_scores = NG_scores.rename(columns={\"Domain\":\"domain\", \"Score\":\"NG_score\"})\n",
    "NG_scores = NG_scores.drop(columns=[\"Last Updated\"])\n",
    "\n",
    "# threshold scores at various cutoffs to define untrustworthy domains\n",
    "NG_scores[\"NG_unreliable\"] = 0\n",
    "NG_scores.loc[NG_scores[NG_scores[\"NG_score\"] < threshold].index, \"NG_unreliable\"] = 1\n",
    "\n",
    "# add the nutrition information to the tweet data table\n",
    "urls = pd.merge(urls, NG_scores,\n",
    "         left_on=\"domain\", right_on=\"domain\", how=\"left\")\n",
    "del NG_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4e71e-2b3e-4443-a9a7-aef9deef614a",
   "metadata": {},
   "source": [
    "## Add alternative trustworthiness labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28a4a1fe-f8c2-4dd9-a93d-db0c7cadc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of independently compiled trustworthiness labels for \n",
    "# news sources\n",
    "src = \"../../data/utilities\"\n",
    "fname = \"independent_labels.csv\"\n",
    "alt_labels = pd.read_csv(join(src, fname))\n",
    "alt_labels = alt_labels.rename(columns = {\n",
    "    \"type\":\"independent_unreliable\", \n",
    "    \"url\":\"domain\"})\n",
    "\n",
    "# convert reliability labels to binary\n",
    "alt_labels[\"independent_unreliable\"] = alt_labels[\"independent_unreliable\"]\\\n",
    "    .replace({\"reliable\":0, \"unreliable\":1})\n",
    "\n",
    "# merge with the tweet data table\n",
    "urls = pd.merge(urls, alt_labels[[\"accuracy\", \"transparency\", \n",
    "        \"independent_unreliable\", \"domain\"]], how=\"left\", left_on=\"domain\",\n",
    "         right_on=\"domain\")\n",
    "del alt_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae920e-36fa-413c-b46c-e005aa0c64b4",
   "metadata": {},
   "source": [
    "## Add truth seeking & belief speaking scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6dafdca3-1193-45a2-b452-768b2324cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the embedding scores for belief-speaking and truth-seeking\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_honesty_component_scores_glove.csv.gzip\"\n",
    "honesty_scores = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    dtype={\"id\":str}, \n",
    "    compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e437f3d0-a725-4d7a-be71-e4ccc78a0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.merge(\n",
    "    honesty_scores, \n",
    "    urls, \n",
    "    how=\"right\", \n",
    "    left_on=\"id\", \n",
    "    right_on=\"id\"\n",
    ")\n",
    "del honesty_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c880a-da0e-4674-a968-cae1147a760e",
   "metadata": {},
   "source": [
    "## Add truth seeking & belief speaking scores for dictionary bootstraps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49736fa-818b-47fa-b7d3-a6db48baeddd",
   "metadata": {},
   "source": [
    "**Note** include this code if you have generated honesty component similarities using the bootstrapped dictionaries by running `label_lexicon_loop.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b189345b-d6f3-4a20-8fe6-645d8458ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_honesty_component_scores_glove_bootstrap.csv.gzip\"\n",
    "honesty_scores_bootstrap = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    dtype={\"id\":str}\n",
    ")\n",
    "\n",
    "urls = pd.merge(\n",
    "    honesty_scores_bootstrap, \n",
    "    urls, \n",
    "    how=\"right\", \n",
    "    left_on=\"id\", \n",
    "    right_on=\"id\"\n",
    ")\n",
    "del honesty_scores_bootstrap\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e8610-dd79-4384-a4c9-962ab6628cf1",
   "metadata": {},
   "source": [
    "## Add party affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8baa890d-8c48-4c33-98ea-e7655f053d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/utilities\"\n",
    "fname = \"party_affiliations_complete.csv\"\n",
    "party_affiliation = pd.read_csv(join(src, fname), dtype={\"author_id\":str})\n",
    "urls = pd.merge(urls, party_affiliation, how=\"left\", left_on=\"author_id\",\n",
    "    right_on=\"author_id\")\n",
    "del party_affiliation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df744784-ba6f-4691-ba80-3b74a9c30075",
   "metadata": {},
   "source": [
    "## Export URLs for article scraping & statistical modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ddbcc04c-f946-4d8f-bace-70449904ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the list of all URLs for article text straping\n",
    "dst = \"../../data/articles/\"\n",
    "fname = \"url_list_for_article_scraping.csv.gzip\"\n",
    "url_export = urls[[\"url\", \"party\"]].copy()\n",
    "url_export = url_export.drop_duplicates().dropna(subset=[\"url\"])\n",
    "url_export.to_csv(join(dst, fname), index=False, compression=\"gzip\")\n",
    "\n",
    "fname = \"url_NG_scores.csv.gzip\"\n",
    "url_export = urls[[\"url\", \"NG_score\"]].copy()\n",
    "url_export = url_export.drop_duplicates().dropna(subset=[\"url\"])\n",
    "url_export.to_csv(join(dst, fname), index=False, compression=\"gzip\")\n",
    "\n",
    "fname = \"url_independent_scores.csv.gzip\"\n",
    "url_export = urls[[\"url\", \"accuracy\", \"transparency\"]].copy()\n",
    "url_export = url_export.drop_duplicates().dropna(subset=[\"url\"])\n",
    "url_export.to_csv(join(dst, fname), index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854407a9-c578-4442-a0de-b671232aaa3a",
   "metadata": {},
   "source": [
    "# Create a tweet data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58b04781-9dad-4f95-bcbf-67ae7fedee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the current \"url\" data frame contains one row per URL, i.e. the same\n",
    "# tweet can be present more than once. To calculate the share of tweets with\n",
    "# unreliable information, we first calculate the mean NewsGuard score (and \n",
    "# mean accuracy and transparency) per tweet by averaging over all scores \n",
    "# of URLs that are present in a given tweet and then assigning \"fishy\" and\n",
    "# \"unreliable\" labels on the tweet level\n",
    "\n",
    "# columns that are defined on the tweet level\n",
    "#tweet_cols = [\"id\", \"author_id\", \"created_at\", \"retweeted\", \"quoted\", \"reply\",\n",
    "#              \"has_url\", \"handle\", \"name\", \"party\"] + \\\n",
    "#             [\"avg_belief_score\", \"avg_truth_score\"] + \\\n",
    "#             [f\"avg_belief_score_{i}\" for i in range(100)] + \\\n",
    "#             [f\"avg_truth_score_{i}\" for i in range(100)]\n",
    "\n",
    "# note: use above columns if you run the script including the dictionary \n",
    "# robustness data\n",
    "tweet_cols = [\"id\", \"author_id\", \"created_at\", \"retweeted\", \"quoted\", \"reply\",\n",
    "              \"has_url\", \"handle\", \"name\", \"party\"] + \\\n",
    "             [\"avg_belief_score\", \"avg_truth_score\"]\n",
    "tweets = urls[tweet_cols].drop_duplicates(subset=[\"id\"]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca01b4-9486-42e8-9b88-d3eb713989d9",
   "metadata": {},
   "source": [
    "## Add LIWC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11fe50d8-a937-4a04-aa14-786ef8ed7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_clean_mask_LIWC.csv.gzip\"\n",
    "cols = [\"id\", \"WC\", \"Analytic\", \"Authentic\", \"moral\", \"emo_pos\", \"emo_neg\"]\n",
    "LIWC_scores = pd.read_csv(\n",
    "    join(src, fname), \n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    dtype={\"id\":str},\n",
    ")\n",
    "LIWC_scores = LIWC_scores.rename(columns={\n",
    "    \"WC\":\"word_count\",\n",
    "    \"Analytic\":\"LIWC_analytic\",\n",
    "    \"Authentic\":\"LIWC_authentic\",\n",
    "    \"moral\":\"LIWC_moral\",\n",
    "    \"emo_pos\":\"LIWC_emo_pos\",\n",
    "    \"emo_neg\":\"LIWC_emo_neg\"\n",
    "})\n",
    "tweets = pd.merge(tweets, LIWC_scores, how=\"left\", left_on=\"id\", right_on=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a6213b-1870-4d10-b0eb-e29437d76fde",
   "metadata": {},
   "source": [
    "## Calculate average NewsGuard score and misinfo components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0fc3332-0793-444f-8764-ae7578b6b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores = urls[[\"id\", \"NG_score\", \"transparency\", \"accuracy\"]]\\\n",
    "    .groupby(\"id\")\\\n",
    "    .agg(\"mean\")\n",
    "\n",
    "average_scores[\"NG_unreliable\"] = np.nan\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"NG_score\"] < 60].index, \"NG_unreliable\"] = 1\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"NG_score\"] >= 60].index, \"NG_unreliable\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490d1c0-59ab-4342-922c-fce0572d5d5e",
   "metadata": {},
   "source": [
    "## Calculate average accuracy & transparency score and unreliable domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f70b5d3-ce28-4609-a8de-52feadeeaefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores[\"independent_unreliable\"] = np.nan\n",
    "# original definition: sources with transparency = 1 are unreliable\n",
    "# since transparency can have non-integer values after averaging, we decide\n",
    "# to label tweets with an average domain transparency value of links of\n",
    "# <= 1.5 as \"unreliable\", since that means that the majority of domains \n",
    "# linked to in the tweet are unreliable. If one domain with transparency 1\n",
    "# and one domain with transparency 2 are linked, the tweet is unreliable\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"transparency\"] <= 1.5].index, \"independent_unreliable\"] = 1\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"transparency\"] > 1.5].index, \"independent_unreliable\"] = 0\n",
    "# original defintion: sources with accuracy = 1 or 2 are unreliable\n",
    "# since accuracy can have non-integer values after averaging, we decide to\n",
    "# label tweets with an average domain accuracy value of links of <= 2.5 as\n",
    "# \"unreliable\", since that means that the majority of domains linked to in \n",
    "# the tweet are unreliable. If one domain with accuracy 2 and one domain \n",
    "# with accuracy 3 are linked, the tweet is unreliable.\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"accuracy\"] <= 2.5].index, \"independent_unreliable\"] = 1\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"accuracy\"] > 2.5].index, \"independent_unreliable\"] = 0\n",
    "\n",
    "tweets = pd.merge(tweets, average_scores, how=\"left\", left_on=\"id\", right_on=\"id\")\n",
    "del average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcce382-f6bf-4ad7-9b57-08ef20082a65",
   "metadata": {},
   "source": [
    "# Create a user data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc2de824-8f53-4876-abf6-01056ffdc0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = tweets[[\"author_id\", \"handle\", \"name\", \"party\", \"id\"]]\\\n",
    "    .groupby([\"author_id\", \"handle\", \"name\", \"party\"])\\\n",
    "    .agg(\"count\")\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"id\":\"N_tweets\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295d1f2-3815-4634-a192-dfa5166f6aa5",
   "metadata": {},
   "source": [
    "## Add account stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd97affd-963c-4ed5-9fcb-74a04207b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/users\"\n",
    "fname = \"US_politician_twitter_accounts_clean.csv\"\n",
    "cols = [\"followers_count\", \"following_count\", \"tweet_count\", \"created_at\", \n",
    "        \"author_id\"]\n",
    "account_stats = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    parse_dates=[\"created_at\"],\n",
    "    usecols=cols,\n",
    "    dtype={\"author_id\":str}\n",
    ")\n",
    "\n",
    "users = pd.merge(users, account_stats, how=\"left\", left_on=\"author_id\", right_on=\"author_id\")\n",
    "del account_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261401b6-eb61-4495-9bdb-a12570397fa0",
   "metadata": {},
   "source": [
    "## Add Congress information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e69ec38a-a3d1-4452-b740-ab537fbe7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/users/clean\"\n",
    "fname = \"congress-member-twitter-handles_114-117.csv\"\n",
    "congress_twitter_handles = pd.read_csv(join(src, fname))\n",
    "congress_twitter_handles = congress_twitter_handles\\\n",
    "    .sort_values(by=\"congress\", ascending=False)\\\n",
    "    .drop_duplicates(subset=\"handle\")\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "users = pd.merge(users, congress_twitter_handles, how=\"left\", left_on=\"handle\",\n",
    "                 right_on=\"handle\")\n",
    "del congress_twitter_handles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11974ba2-c6c1-42fa-9d99-bc1f1b949fd6",
   "metadata": {},
   "source": [
    "## Add share of untrustworthy domains (NewsGuard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a056d98f-6208-40d2-bb48-68e7861ac7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>NG_unreliable_sum</th>\n",
       "      <th>NG_unreliable_count</th>\n",
       "      <th>NG_unreliable_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009269193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011053278304592000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id  NG_unreliable_sum  NG_unreliable_count  \\\n",
       "0           1009269193                0.0                  221   \n",
       "1  1011053278304592000                0.0                    0   \n",
       "\n",
       "   NG_unreliable_share  \n",
       "0                  0.0  \n",
       "1                  NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"author_id\", \"NG_unreliable\"]\n",
    "unreliable_user_count = tweets[tweets[\"retweeted\"] == False][cols]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .agg([\"sum\", \"count\"])\n",
    "\n",
    "unreliable_user_count[\"NG_unreliable_share\"] = \\\n",
    "    unreliable_user_count[\"NG_unreliable\"][\"sum\"] / \\\n",
    "    unreliable_user_count[\"NG_unreliable\"][\"count\"]\n",
    "    \n",
    "# flatten the hierarchical indices\n",
    "unreliable_user_count = unreliable_user_count.reset_index()\n",
    "unreliable_user_count.columns = ['_'.join(col).strip(\"_\") \\\n",
    "                            for col in unreliable_user_count.columns.values]\n",
    "\n",
    "unreliable_user_count.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e070f70f-4543-4858-be3e-cf2bded68125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"NG_unreliable_share\", \"author_id\"]\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    unreliable_user_count[cols],\n",
    "    how=\"left\",\n",
    "    left_on=\"author_id\",\n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1daea-e29c-4328-b1c2-05f8e18f3a0b",
   "metadata": {},
   "source": [
    "## Add average NewsGuard score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7b53b46-f10e-4ef0-93e9-e86325f82211",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_NG_scores = tweets[tweets[\"retweeted\"] == False][[\"author_id\", \"NG_score\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"NG_score\":\"NG_score_mean\"})\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    average_NG_scores, \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6307c56-adfd-4d83-b111-9bb2e8461225",
   "metadata": {},
   "source": [
    "## Add average accuracy & transparency score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d17fb525-9a04-4192-8d16-7729d7041660",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy_transparency = tweets[tweets[\"retweeted\"] == False]\\\n",
    "    [[\"author_id\", \"accuracy\", \"transparency\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\n",
    "        \"accuracy\":\"accuracy_mean\",\n",
    "        \"transparency\":\"transparency_mean\"\n",
    "    })\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    average_accuracy_transparency, \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a4007-d097-44f5-a790-14bc31711dec",
   "metadata": {},
   "source": [
    "## Add share of unstrustworthy domains (independent list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40b07a89-36ca-4677-a73b-e853a1a20029",
   "metadata": {},
   "outputs": [],
   "source": [
    "unreliable_user_count = tweets[tweets[\"retweeted\"] == False]\\\n",
    "    [[\"author_id\", \"independent_unreliable\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .agg([\"sum\", \"count\"])\n",
    "\n",
    "unreliable_user_count[\"independent_unreliable_share\"] = \\\n",
    "    unreliable_user_count[\"independent_unreliable\"][\"sum\"] / \\\n",
    "    unreliable_user_count[\"independent_unreliable\"][\"count\"]\n",
    "    \n",
    "# flatten the hierarchical indices\n",
    "unreliable_user_count = unreliable_user_count.reset_index()\n",
    "unreliable_user_count.columns = ['_'.join(col).strip(\"_\") \\\n",
    "                            for col in unreliable_user_count.columns.values]\n",
    "\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    unreliable_user_count[[\"author_id\", \"independent_unreliable_share\"]],\n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "del unreliable_user_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20835b75-393f-43b7-a90d-1052d64f34e8",
   "metadata": {},
   "source": [
    "## Add average belief-speaking and truth-seeking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11c755fd-f871-4c72-9143-70f9c48bb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "honesty_tweets_score = tweets[tweets[\"retweeted\"] == False]\\\n",
    "    [[\"author_id\", \"avg_belief_score\", \"avg_truth_score\", \"created_at\"]]\\\n",
    "    .dropna(subset=[\"avg_belief_score\", \"avg_truth_score\"])\\\n",
    "    .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bb06c889-9244-4d11-871d-19fdf897b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all honesty component tweets\n",
    "honesty_score_average = honesty_tweets_score\\\n",
    "    [[\"author_id\", \"avg_belief_score\", \"avg_truth_score\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\n",
    "\n",
    "honesty_score_average = honesty_score_average.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe8cfb14-8b77-451c-87ee-0334ed4a0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "honesty_tweets_score = honesty_tweets_score.set_index(\"created_at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a38b5189-4dc6-4b77-8eee-459adee64e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only first 4 years\n",
    "honesty_score_average_first = honesty_tweets_score[honesty_tweets_score.index.year <= 2013]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\n",
    "\n",
    "honesty_score_average_first = honesty_score_average_first.reset_index()\n",
    "cols = [\"avg_belief_score\", \"avg_truth_score\"]\n",
    "honesty_score_average_first = honesty_score_average_first\\\n",
    "    .rename(columns={col:col + \"_2010_to_2013\" for col in cols}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e0e16e6d-4285-4467-af72-725c68fa1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only last 4 years\n",
    "honesty_score_average_last = honesty_tweets_score[honesty_tweets_score.index.year >= 2019]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\n",
    "honesty_score_average_last = honesty_score_average_last.reset_index()\n",
    "cols = [\"avg_belief_score\", \"avg_truth_score\"]\n",
    "honesty_score_average_last = honesty_score_average_last\\\n",
    "    .rename(columns={col:col + \"_2019_to_2022\" for col in cols}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a512ab21-cf2c-4ed1-9c59-7fae1e05ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.merge(honesty_score_average[[\"author_id\", \"avg_belief_score\", \n",
    "                    \"avg_truth_score\"]], how=\"left\", left_on=\"author_id\", \n",
    "                    right_on=\"author_id\")\n",
    "del honesty_score_average\n",
    "\n",
    "users = users.merge(\n",
    "    honesty_score_average_first,\n",
    "    how=\"left\",\n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "del honesty_score_average_first\n",
    "\n",
    "users = users.merge(\n",
    "    honesty_score_average_last,\n",
    "    how=\"left\",\n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "del honesty_score_average_last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ebb33-9474-4a43-9c1a-92a1d10c950f",
   "metadata": {},
   "source": [
    "## Add average emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d48e23f5-70d8-4dd8-ac44-f69c5d1a83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['LIWC_analytic', 'LIWC_authentic', 'LIWC_emo_pos',\n",
    "            'LIWC_emo_neg', 'LIWC_moral']\n",
    "average_emotion_scores = tweets[tweets[\"retweeted\"] == False]\\\n",
    "    [[\"author_id\"] + emotions]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\\\n",
    "    .reset_index()\n",
    "emotion_map = {em:f\"{em}_mean\" for em in emotions}\n",
    "average_emotion_scores = average_emotion_scores.rename(columns=emotion_map)\n",
    "\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    average_emotion_scores, \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d5df9-59f6-42d8-85e7-8c3702603805",
   "metadata": {},
   "source": [
    "## Add ideology scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e77d54eb-c6c5-4ca6-9980-9dec16b0b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/utilities\"\n",
    "fname = \"govtrack-stats-{}-{}-ideology.csv\"\n",
    "ideology_scores = pd.DataFrame()\n",
    "for year in range(2013, 2021):\n",
    "    for chamber in [\"house\", \"senate\"]:\n",
    "        tmp = pd.read_csv(join(src, \"ideology_scores\",\n",
    "                               fname.format(year, chamber)))\n",
    "        tmp[\"year\"] = year\n",
    "        tmp[\"name\"] = tmp[\"name\"].apply(lambda x: x.replace(\"b'\", \"\"))\n",
    "        tmp[\"name\"] = tmp[\"name\"].apply(lambda x: x.replace(\"'\", \"\").lower())\n",
    "        ideology_scores = pd.concat([ideology_scores, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4225918e-470e-4139-a980-d1c97587e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match politician Twitter account names to govtrack politician names\n",
    "\n",
    "# a single politician can have at maximum 8 entries for 8 different years\n",
    "# 2013 to 2020\n",
    "counts = ideology_scores[\"name\"].value_counts()\n",
    "unique_names = list(counts[counts <= 8].index)\n",
    "\n",
    "unique_scores = ideology_scores[ideology_scores[\"name\"].isin(unique_names)]\\\n",
    "    .sort_values(by=\"year\", ascending=False)\\\n",
    "    .drop_duplicates(subset=[\"name\"])\\\n",
    "    .set_index(\"name\")\n",
    "unique_names = list(set(unique_scores.index))\n",
    "\n",
    "def match_score(account_name):\n",
    "    '''Matches govtrack politician names to Twitter account names.'''\n",
    "    if account_name == account_name:\n",
    "        account_name = set(account_name.lower().split(\" \"))\n",
    "        for name in unique_names:\n",
    "            # hard matching: if the govtrack name string is completely included\n",
    "            # in the Twitter account name string, record a match\n",
    "            if name in account_name:\n",
    "                return unique_scores.loc[name][\"id\"]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "users[\"ideology_score_id\"] = users[\"name\"].apply(match_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28e6f597-1240-4040-a814-8fab957ba0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hand-matched missing scores\n",
    "src = \"../../data/utilities\"\n",
    "fname = \"missing_govtrack_ideology_scores.csv\"\n",
    "missing_scores = pd.read_csv(join(src, fname))\n",
    "missing_scores = {row[\"handle\"]:row[\"ideology_score_id\"] \\\n",
    "                  for i, row in missing_scores.iterrows()}\n",
    "\n",
    "# index on the handle since this seems to be the most consistent index between\n",
    "# the two datasets\n",
    "users = users.set_index(\"handle\")\n",
    "for handle, score_id in missing_scores.items():\n",
    "    if handle in users.index:\n",
    "        users.loc[handle, \"ideology_score_id\"] = score_id\n",
    "users = users.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "970b5966-4348-4e4a-b270-9f7b87177fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for many accounts, there is more than one ideology score since they were \n",
    "# active over many years. We calculate the mean, std and count of the ideology\n",
    "# score for each user and add this information to the user_df\n",
    "ideology_scores_agg = ideology_scores[[\"id\", \"ideology\"]]\\\n",
    "    .groupby(\"id\")\\\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "ideology_scores_agg = ideology_scores_agg.reset_index()\n",
    "ideology_scores_agg.columns = ['_'.join(col).strip(\"_\") \\\n",
    "                            for col in ideology_scores_agg.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "74895b07-eee3-4235-8818-e5c9e2f799e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.merge(ideology_scores_agg, how=\"left\", \n",
    "                      left_on=\"ideology_score_id\", right_on=\"id\")\n",
    "del ideology_scores\n",
    "del ideology_scores_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e52b7e7-4487-4e38-a701-e572c43930dc",
   "metadata": {},
   "source": [
    "## Add Politifact scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cc203c1d-6d46-413d-a1b5-2fb3a1e88b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/utilities\"\n",
    "fname = \"misinfo_score_politifact.csv\"\n",
    "pf_scores = pd.read_csv(join(src, fname), \n",
    "        usecols=[\"pf_score\", \"elite_account\"])\\\n",
    "    .rename(columns={\"elite_account\":\"handle\"})\n",
    "\n",
    "users = pd.merge(users, pf_scores, how=\"left\", left_on=\"handle\", right_on=\"handle\")\n",
    "del pf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c0265-fecb-4048-bd50-802e4eeb3177",
   "metadata": {},
   "source": [
    "# Data exports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce73d2-f5f7-4a27-b46b-7c11abcc2f82",
   "metadata": {},
   "source": [
    "## URL, tweet and user data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ace989-47ce-4966-9ec8-21da8180e4ae",
   "metadata": {},
   "source": [
    "**Note**: if you are running this code including the data for the dictionary robustness ananlysis, saving the files takes a while because they are pretty large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f0fcc5e-1982-4323-801c-6614c8250d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38c29338-6b28-41e7-b93c-c2ae005d9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL data frame\n",
    "fname = \"US_politician_URLs_2010-11-06_to_2022-03-16.csv.gzip\"\n",
    "urls = urls[urls[\"has_url\"] == True]\n",
    "urls = urls.drop(columns=[\"url\", \"status_code\", \"handle\", \"name\", \"has_url\"])\n",
    "urls.to_csv(join(dst, \"urls\", fname), index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d12e8d4-6651-4dc0-988a-fca8d50be901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user data frame\n",
    "fname = \"users.csv\"\n",
    "users = users.drop(columns=[\"ideology_score_id\", \"id\"])\n",
    "users.to_csv(join(dst, \"users\", fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e2e6b858-14f8-40d0-bdc4-7ad842836fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet data frame\n",
    "fname = \"US_politician_tweets_2010-11-06_to_2022-03-16.csv.gzip\"\n",
    "tweets = tweets.drop(columns=[\"handle\", \"name\"])\n",
    "tweets.to_csv(join(dst, \"tweets\", fname), index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a69d5c-fc6a-43f1-ad6b-d7d8dad5ba10",
   "metadata": {},
   "source": [
    "## Data for linear mixed effects modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f049be3-2d6e-4d26-92d3-7c5b2953cb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1791859"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    \"retweeted\", # used to filter out retweets\n",
    "    \"author_id\", # data grouping: independent random variable\n",
    "    \"party\", # characteristic of author: independent fixed variable\n",
    "    \"avg_belief_score\", # fixed variable\n",
    "    \"avg_truth_score\", # fixed variable\n",
    "    \"NG_score\", # dependent variable\n",
    "    \"accuracy\", # dependent variable\n",
    "    \"transparency\", # dependent variable\n",
    "]\n",
    "tweets_lme = tweets[cols].copy()\n",
    "tweets_lme = tweets_lme[tweets_lme[\"retweeted\"] == False] # remove retweets\n",
    "tweets_lme = tweets_lme.drop(columns=[\"retweeted\"])\n",
    "tweets_lme = tweets_lme[tweets_lme[\"party\"].isin([\"Democrat\", \"Republican\"])] # remove independents\n",
    "tweets_lme = tweets_lme.dropna(subset=[\"avg_belief_score\", \"avg_truth_score\"]) # remove tweets without NG, belief or truth score\n",
    "len(tweets_lme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e430679d-0658-4067-a0f4-b29781eecdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1791858"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out authors with only a single tweet\n",
    "tweet_counts = tweets_lme[\"author_id\"]\\\n",
    "    .value_counts()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"index\":\"author_id\", \"author_id\":\"count\"})\n",
    "\n",
    "tweets_lme = tweets_lme[tweets_lme[\"author_id\"].isin(tweet_counts[tweet_counts[\"count\"] > 1][\"author_id\"])]\n",
    "len(tweets_lme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c950f2c4-7dc9-41ae-8f50-63cc062b16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"author_id\", \"ideology_mean\"]\n",
    "users_lme = users[cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b4b94e0-494c-42b4-abf0-13cd5861d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_lme = pd.merge(\n",
    "    tweets_lme,\n",
    "    users_lme,\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "052e9fb5-4725-4581-8f32-309ac68b8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center similarity scores\n",
    "tweets_lme[\"belief\"] = tweets_lme[\"avg_belief_score\"] - tweets_lme[\"avg_belief_score\"].mean()\n",
    "tweets_lme[\"truth\"] = tweets_lme[\"avg_truth_score\"] - tweets_lme[\"avg_truth_score\"].mean()\n",
    "# normalize trustworthiness scores by maximum scale value\n",
    "tweets_lme[\"NG\"] = tweets_lme[\"NG_score\"] / 100\n",
    "tweets_lme[\"accuracy\"] = tweets_lme[\"accuracy\"] / 5\n",
    "tweets_lme[\"transparency\"] = tweets_lme[\"transparency\"] / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23745734-9a7d-4741-a5bc-9288a93e96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"author_id\", \"party\", \"belief\", \"truth\"]\n",
    "# only tweets that have a NewsGuard score\n",
    "tweets_NG = tweets_lme[cols + [\"NG\"]].dropna()\n",
    "# only tweets that have an accuracy/transparency score\n",
    "tweets_independent = tweets_lme[cols + [\"accuracy\", \"transparency\"]].dropna()\n",
    "\n",
    "dst = \"../../data/tweets\"\n",
    "tweets_NG.to_csv(join(dst, \"tweets_for_lme_modelling_NG.csv\"), index=False)\n",
    "tweets_independent.to_csv(join(dst, \"tweets_for_lme_modelling_independent.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79faab80-ddda-4055-9ff5-f469bbadab81",
   "metadata": {},
   "source": [
    "## Data for topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8d156dcf-399b-47b3-90b1-49f189a4951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the tweet data\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_clean.csv.gzip\"\n",
    "cols = [\"id\", \"author_id\", \"text\"]\n",
    "tweets = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    dtype={\"id\":str, \"author_id\":str}\n",
    ")\n",
    "tweets[\"id\"] = tweets[\"id\"].str.replace('\"', '')\n",
    "tweets[\"author_id\"] = tweets[\"author_id\"].str.replace('\"', '')\n",
    "\n",
    "# read the honesty scores\n",
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_honesty_component_scores_glove.csv.gzip\"\n",
    "cols = [\"id\", \"avg_belief_score\", \"avg_truth_score\"]\n",
    "honesty_scores = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    dtype={\"id\":str}\n",
    ")\n",
    "\n",
    "# add honesty component scores\n",
    "tweets = pd.merge(\n",
    "    tweets,\n",
    "    honesty_scores,\n",
    "    how=\"left\",\n",
    "    left_on=\"id\",\n",
    "    right_on=\"id\"\n",
    ")\n",
    "\n",
    "# add party information\n",
    "tweets = pd.merge(\n",
    "    tweets,\n",
    "    users[[\"author_id\", \"party\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"author_id\",\n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "\n",
    "# drop all tweets without party and honesty score information (retweets and\n",
    "# tweets with too short text that don't have honesty scores)\n",
    "tweets = tweets.dropna()\n",
    "\n",
    "# drop all tweets that are not from Democrats or Republicans\n",
    "tweets = tweets[tweets[\"party\"].isin([\"Democrat\", \"Republican\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1526c543-c5a8-42f7-8e64-e7c681759c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize text - note: this takes a while\n",
    "from pandarallel import pandarallel\n",
    "import spacy\n",
    "pandarallel.initialize(nb_workers=8)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "tweets[\"lemmatized\"] = tweets['text']\\\n",
    "    .parallel_apply(lambda x: \" \".join([y.lemma_ for y in nlp(x)]))\n",
    "\n",
    "tweets['lemmatized'] = tweets['lemmatized'].str.replace(r'\\s+|\\\\n', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201ac46-9c07-41f3-a3f2-ce350780ef31",
   "metadata": {},
   "source": [
    "## Calculate quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f1c570bd-25ad-464d-8ca4-dd8bca6ff0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify tweets that are in the top belief-speaking similarity and \n",
    "# truth-seeking similarity quantiles and assign them to the \"belief\" and \"truth\"\n",
    "# categories. If a tweet is in both top quantiles, assign them to the category\n",
    "# with the higher similarity\n",
    "belief_quant = tweets[\"avg_belief_score\"].quantile(0.8)\n",
    "truth_quant = tweets[\"avg_truth_score\"].quantile(0.8)\n",
    "tweets[\"belief\"] = 0\n",
    "tweets[\"truth\"] = 0\n",
    "\n",
    "# assign categories based on quantiles\n",
    "tweets.loc[tweets[tweets[\"avg_belief_score\"] >= belief_quant].index, \"belief\"] = 1\n",
    "tweets.loc[tweets[tweets[\"avg_truth_score\"] >= truth_quant].index, \"truth\"] = 1\n",
    "\n",
    "# tweets that are in both categories\n",
    "tweets.loc[tweets[\n",
    "    (tweets[\"belief\"] == 1) & (tweets[\"truth\"] == 1) & \\\n",
    "    (tweets[\"avg_belief_score\"] > tweets[\"avg_truth_score\"])].index, \"truth\"] = 0\n",
    "tweets.loc[tweets[\n",
    "    (tweets[\"belief\"] == 1) & (tweets[\"truth\"] == 1) & \\\n",
    "    (tweets[\"avg_truth_score\"] > tweets[\"avg_belief_score\"])].index, \"belief\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b19ce406-8495-48e1-8bd2-754dd0a57b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign tweets to honesty component X party categories\n",
    "tweets[\"classes_quant\"] = np.nan\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Democrat\") & (tweets[\"belief\"] == 1)].index, \"classes_quant\"] = \"db\"\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Democrat\") & (tweets[\"truth\"] == 1)].index, \"classes_quant\"] = \"dt\"\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Republican\") & (tweets[\"belief\"] == 1)].index, \"classes_quant\"] = \"rb\"\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Republican\") & (tweets[\"truth\"] == 1)].index, \"classes_quant\"] = \"rt\"\n",
    "\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Democrat\") & (tweets[\"belief\"] == 0) & (tweets[\"truth\"] == 0)].index, \"classes_quant\"] = \"dn\"\n",
    "tweets.loc[tweets[(tweets[\"party\"] == \"Republican\") & (tweets[\"belief\"] == 0) & (tweets[\"truth\"] == 0)].index, \"classes_quant\"] = \"rn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5e6574eb-2cd2-40cd-87fd-4a62cb2c728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "dst = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_lemma.csv.gzip\"\n",
    "cols = [\"id\", \"author_id\", \"lemmatized\", \"party\", \"avg_belief_score\",\n",
    "        \"avg_truth_score\", \"classes_quant\"]\n",
    "tweets[cols].to_csv(\n",
    "    join(dst, fname),\n",
    "    compression=\"gzip\",\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
