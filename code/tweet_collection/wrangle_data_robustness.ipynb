{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316acf0-df86-4849-bfce-ae80cceac5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Jana Lasser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d70086-b0cd-471d-867d-21e782483b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139da757-f9f3-4839-b4e8-224adf5dafd7",
   "metadata": {},
   "source": [
    "# Create a URL data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9287984-bfed-41cd-b853-226df27367c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data frame with the expanded URLs\n",
    "src = \"../../data/urls\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2021-03-16_clean_urls.csv.gzip\"\n",
    "cols = [\"id\", \"author_id\", \"created_at\", \"url\", \"retweeted\",\n",
    "        \"quoted\", \"reply\", \"has_url\"]\n",
    "urls = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    parse_dates=[\"created_at\"],\n",
    "    dtype={\"author_id\":str, \"id\":str}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d582d2-3902-4505-b3f2-912132db85ba",
   "metadata": {},
   "source": [
    "## Add unraveled URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a307d6-8c0f-4f81-943f-2224dde5809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of originally shortened URLs with their expansions to their true\n",
    "# destination\n",
    "src = \"../../data/urls\"\n",
    "fname = \"US_unraveled_urls.csv.xz\"\n",
    "unraveled_urls = pd.read_csv(join(src, fname), compression=\"xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99817340-0e3c-4ff3-bf3f-39e28d4c712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add URL information\n",
    "urls = pd.merge(urls, unraveled_urls, left_on=\"url\", right_on=\"url\", how=\"left\")\n",
    "\n",
    "# add indicator of whether the URL was originally shortened\n",
    "urls[\"shortened_url\"] = False\n",
    "urls.loc[urls[\"unraveled_url\"].dropna().index, \"shortened_url\"] = True\n",
    "\n",
    "# replace the shortened URL with the unraveled URL\n",
    "urls.loc[urls[\"unraveled_url\"].dropna().index, \"url\"] = \\\n",
    "    urls.loc[urls[\"unraveled_url\"].dropna().index, \"unraveled_url\"]\n",
    "urls = urls.drop(columns=[\"unraveled_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb618ca-2d99-4b12-b55d-34cba20edadf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found malformed URL https\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n",
      "found malformed URL http\n"
     ]
    }
   ],
   "source": [
    "# extract the domain from the URL\n",
    "def extract_domain(url):\n",
    "    '''Given an ULR, extracts the domain name in the form XXXXX.YY'''\n",
    "    if url != url:\n",
    "        return np.nan\n",
    "    # reformat entries that have the domain after a general name in parantheses\n",
    "    if url.find('(') > 0:\n",
    "        url = url.split('(')[-1]\n",
    "        url = url.strip(')')\n",
    "    # trailing \"/\" and spaces\n",
    "    url = url.strip('/').strip()\n",
    "    # transform all domains to lowercase\n",
    "    url = url.lower()\n",
    "    # remove any white spaces\n",
    "    url = url.replace(' ', '')\n",
    "    # if present: remove the protocol\n",
    "    if url.startswith((\"http\", \"https\")):\n",
    "        try:\n",
    "            url = url.split('//')[1]\n",
    "        except IndexError:\n",
    "            print(f\"found malformed URL {url}\")\n",
    "            return np.nan\n",
    "    # remove \"www.\" \n",
    "    url = url.replace('www.', '')\n",
    "    url = url.split(\"/\")[0]\n",
    "    return url\n",
    "\n",
    "urls[\"domain\"] = urls[\"url\"].apply(extract_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beecaea6-0097-46bd-81ba-447d54aedbe7",
   "metadata": {},
   "source": [
    "## Add NewsGuard nutrition scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bd17d-6a55-4776-bb34-082cf521baf6",
   "metadata": {},
   "source": [
    "Newsguard rating cutoff: 60 (see [description](https://www.newsguardtech.com/ratings/rating-process-criteria/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e27eb7a1-a3c0-4b14-8cd3-3b003a6d0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the nutrition labels\n",
    "src = \"../../data/utilities/\"\n",
    "fname = \"NewsGuard_labels.csv\"\n",
    "cols = [\"Domain\", \"Score\", \"Last Updated\"]\n",
    "NG_scores = pd.read_csv(join(src, fname), usecols=cols)\n",
    "# if more than one score exists for the same domain, keep the most recent one\n",
    "NG_scores = NG_scores.sort_values(by=[\"Domain\",\"Last Updated\"], ascending=False)\n",
    "NG_scores = NG_scores.drop_duplicates(subset=[\"Domain\"])\n",
    "NG_scores = NG_scores.rename(columns={\"Domain\":\"domain\", \"Score\":\"NG_score\"})\n",
    "NG_scores = NG_scores.drop(columns=[\"Last Updated\"])\n",
    "\n",
    "# threshold scores at various cutoffs to define untrustworthy domains\n",
    "NG_scores[\"NG_unreliable\"] = 0\n",
    "NG_scores.loc[NG_scores[NG_scores[\"NG_score\"] < 60].index, \"NG_unreliable\"] = 1\n",
    "\n",
    "# add the nutrition information to the tweet data table\n",
    "urls = pd.merge(urls, NG_scores,\n",
    "         left_on=\"domain\", right_on=\"domain\", how=\"left\")\n",
    "del NG_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddbcc04c-f946-4d8f-bace-70449904ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the list of all URLs with a NewsGuard score for article text straping\n",
    "dst = \"../../data/urls/\"\n",
    "fname = \"url_list_for_article_scraping.csv.gzip\"\n",
    "url_export = urls[[\"url\", \"domain\", \"NG_score\"]].copy()\n",
    "url_export = url_export.drop_duplicates().dropna(subset=[\"url\"])\n",
    "url_export.to_csv(join(dst, fname), index=False, compression=\"gzip\")\n",
    "del url_export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4e71e-2b3e-4443-a9a7-aef9deef614a",
   "metadata": {},
   "source": [
    "## Add alternative trustworthiness labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a4a1fe-f8c2-4dd9-a93d-db0c7cadc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of independently compiled trustworthiness labels for \n",
    "# news sources\n",
    "src = \"../../data/utilities\"\n",
    "fname = \"independent_labels.csv\"\n",
    "alt_labels = pd.read_csv(join(src, fname))\n",
    "alt_labels = alt_labels.rename(columns = {\n",
    "    \"type\":\"independent_unreliable\", \n",
    "    \"url\":\"domain\"})\n",
    "\n",
    "# convert reliability labels to binary\n",
    "alt_labels[\"independent_unreliable\"] = alt_labels[\"independent_unreliable\"]\\\n",
    "    .replace({\"reliable\":0, \"unreliable\":1})\n",
    "\n",
    "# merge with the tweet data table\n",
    "urls = pd.merge(urls, alt_labels[[\"accuracy\", \"transparency\", \n",
    "        \"independent_unreliable\", \"domain\"]], how=\"left\", left_on=\"domain\",\n",
    "         right_on=\"domain\")\n",
    "del alt_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae920e-36fa-413c-b46c-e005aa0c64b4",
   "metadata": {},
   "source": [
    "## Add truth seeking & belief speaking scores for different embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "549d5038-ec5e-45b3-a50c-99089a5a3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_p0.05_swapped_label_DDR_glove840B.csv.zip\"\n",
    "cols = [\"id\", \"avg_belief_score\", \"avg_truth_score\"]\n",
    "honesty_scores_glove = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    usecols=cols,\n",
    "    compression=\"zip\"\n",
    ")\n",
    "honesty_scores_glove[\"id\"] = honesty_scores_glove[\"id\"].apply(lambda x: x.replace('\"', ''))\n",
    "honesty_scores_glove = honesty_scores_glove.rename(columns={\n",
    "    \"avg_belief_score\":\"avg_belief_score_glove\",\n",
    "    \"avg_truth_score\":\"avg_truth_score_glove\"\n",
    "})\n",
    "\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_p0.05_swapped_label_DDR_word2vec.csv.xz\"\n",
    "honesty_scores_word2vec = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    usecols=cols,\n",
    "    compression=\"xz\"\n",
    ")\n",
    "honesty_scores_word2vec[\"id\"] = honesty_scores_word2vec[\"id\"].apply(lambda x: x.replace('\"', ''))\n",
    "honesty_scores_word2vec = honesty_scores_word2vec.rename(columns={\n",
    "    \"avg_belief_score\":\"avg_belief_score_word2vec\",\n",
    "    \"avg_truth_score\":\"avg_truth_score_word2vec\"\n",
    "})\n",
    "\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_p0.05_swapped_label_DDR_fasttext.csv.xz\"\n",
    "honesty_scores_fasttext = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    usecols=cols,\n",
    "    compression=\"xz\"\n",
    ")\n",
    "honesty_scores_fasttext[\"id\"] = honesty_scores_fasttext[\"id\"].apply(lambda x: x.replace('\"', ''))\n",
    "honesty_scores_fasttext = honesty_scores_fasttext.rename(columns={\n",
    "    \"avg_belief_score\":\"avg_belief_score_fasttext\",\n",
    "    \"avg_truth_score\":\"avg_truth_score_fasttext\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e437f3d0-a725-4d7a-be71-e4ccc78a0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.merge(honesty_scores_glove[[\"id\", \"avg_belief_score_glove\", \"avg_truth_score_glove\"]], \n",
    "         urls, how=\"right\", left_on=\"id\", right_on=\"id\")\n",
    "urls = pd.merge(honesty_scores_word2vec[[\"id\", \"avg_belief_score_word2vec\", \"avg_truth_score_word2vec\"]], \n",
    "         urls, how=\"right\", left_on=\"id\", right_on=\"id\")\n",
    "urls = pd.merge(honesty_scores_fasttext[[\"id\", \"avg_belief_score_fasttext\", \"avg_truth_score_fasttext\"]], \n",
    "         urls, how=\"right\", left_on=\"id\", right_on=\"id\")\n",
    "del honesty_scores_glove\n",
    "del honesty_scores_word2vec\n",
    "del honesty_scores_fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1eeb79-b489-4e14-9e87-01b78bccbac6",
   "metadata": {},
   "source": [
    "## Add truth seeking & belief speaking scores for dictionary bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8add3bf0-2e43-48cc-bda7-4b90f1ccab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_p0.05_swapped_label_DDR_glove840B_loop.csv.xz\"\n",
    "honesty_scores_bootstrap = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    compression=\"xz\"\n",
    ")\n",
    "honesty_scores_bootstrap[\"id\"] = honesty_scores_bootstrap[\"id\"].apply(lambda x: x.replace('\"', ''))\n",
    "cols = [c for c in honesty_scores_bootstrap.columns if not c in [\"author_id\", \"conversation_id\"]]\n",
    "honesty_scores_bootstrap = honesty_scores_bootstrap[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9c2b0eb-2d48-4832-9e18-ca82ec11cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.merge(\n",
    "    honesty_scores_bootstrap, \n",
    "    urls, \n",
    "    how=\"right\", \n",
    "    left_on=\"id\", \n",
    "    right_on=\"id\"\n",
    ")\n",
    "del honesty_scores_bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e8610-dd79-4384-a4c9-962ab6628cf1",
   "metadata": {},
   "source": [
    "## Add party affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8baa890d-8c48-4c33-98ea-e7655f053d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/utilities\"\n",
    "fname = \"party_affiliations_complete.csv\"\n",
    "party_affiliation = pd.read_csv(join(src, fname), dtype={\"author_id\":str})\n",
    "urls = pd.merge(urls, party_affiliation, how=\"left\", left_on=\"author_id\",\n",
    "    right_on=\"author_id\")\n",
    "del party_affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c9c582d-ee2a-4200-8a14-adb50b39bf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'avg_truth_score_0', 'avg_truth_score_1', 'avg_truth_score_2',\n",
       "       'avg_truth_score_3', 'avg_truth_score_4', 'avg_truth_score_5',\n",
       "       'avg_truth_score_6', 'avg_truth_score_7', 'avg_truth_score_8',\n",
       "       ...\n",
       "       'shortened_url', 'domain', 'NG_score', 'NG_unreliable', 'accuracy',\n",
       "       'transparency', 'independent_unreliable', 'handle', 'name', 'party'],\n",
       "      dtype='object', length=225)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854407a9-c578-4442-a0de-b671232aaa3a",
   "metadata": {},
   "source": [
    "# Create a tweet data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58b04781-9dad-4f95-bcbf-67ae7fedee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the current \"url\" data frame contains one row per URL, i.e. the same\n",
    "# tweet can be present more than once. To calculate the share of tweets with\n",
    "# unreliable information, we first calculate the mean NewsGuard score (and \n",
    "# mean accuracy and transparency) per tweet by averaging over all scores \n",
    "# of URLs that are present in a given tweet and then assigning \"fishy\" and\n",
    "# \"unreliable\" labels on the tweet level\n",
    "\n",
    "# columns that are defined on the tweet level\n",
    "tweet_cols = [\"id\", \"author_id\", \"created_at\", \"retweeted\", \"quoted\", \"reply\",\n",
    "              \"has_url\", \"handle\", \"name\", \"party\"] + \\\n",
    "             [f\"avg_truth_score_{i}\" for i in range(100)] + \\\n",
    "             [f\"avg_belief_score_{i}\" for i in range(100)] + \\\n",
    "             [\"avg_truth_score_glove\", \"avg_truth_score_word2vec\", \"avg_truth_score_fasttext\"] + \\\n",
    "             [\"avg_belief_score_glove\", \"avg_belief_score_word2vec\", \"avg_belief_score_fasttext\"]\n",
    "tweets = urls[tweet_cols].drop_duplicates(subset=[\"id\"]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca01b4-9486-42e8-9b88-d3eb713989d9",
   "metadata": {},
   "source": [
    "## Add LIWC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11fe50d8-a937-4a04-aa14-786ef8ed7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/tweets\"\n",
    "fname = \"combined_US_politician_twitter_timelines_2010-11-06_to_2022-03-16_clean_mask_LIWC.csv.gzip\"\n",
    "cols = [\"id\", \"WC\", \"Analytic\", \"Authentic\", \"moral\", \"emo_pos\", \"emo_neg\"]\n",
    "LIWC_scores = pd.read_csv(\n",
    "    join(src, fname), \n",
    "    compression=\"gzip\",\n",
    "    usecols=cols,\n",
    "    dtype={\"id\":str},\n",
    ")\n",
    "LIWC_scores = LIWC_scores.rename(columns={\n",
    "    \"WC\":\"word_count\",\n",
    "    \"Analytic\":\"LIWC_analytic\",\n",
    "    \"Authentic\":\"LIWC_authentic\",\n",
    "    \"moral\":\"LIWC_moral\",\n",
    "    \"emo_pos\":\"LIWC_emo_pos\",\n",
    "    \"emo_neg\":\"LIWC_emo_neg\"\n",
    "})\n",
    "tweets = pd.merge(tweets, LIWC_scores, how=\"left\", left_on=\"id\", right_on=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a6213b-1870-4d10-b0eb-e29437d76fde",
   "metadata": {},
   "source": [
    "## Calculate average NewsGuard score and misinfo components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0fc3332-0793-444f-8764-ae7578b6b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores = urls[[\"id\", \"NG_score\", \"transparency\", \"accuracy\"]]\\\n",
    "    .groupby(\"id\")\\\n",
    "    .agg(\"mean\")\n",
    "\n",
    "average_scores[\"NG_unreliable\"] = np.nan\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"NG_score\"] < 60].index, \"NG_unreliable\"] = 1\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"NG_score\"] >= 60].index, \"NG_unreliable\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490d1c0-59ab-4342-922c-fce0572d5d5e",
   "metadata": {},
   "source": [
    "## Calculate average accuracy & transparency score and unreliable domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f70b5d3-ce28-4609-a8de-52feadeeaefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores[\"independent_unreliable\"] = np.nan\n",
    "# original definition: sources with transparency = 1 are unreliable\n",
    "# since transparency can have non-integer values after averaging, we decide\n",
    "# to label tweets with an average domain transparency value of links of\n",
    "# <= 1.5 as \"unreliable\", since that means that the majority of domains \n",
    "# linked to in the tweet are unreliable. If one domain with transparency 1\n",
    "# and one domain with transparency 2 are linked, the tweet is unreliable\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"transparency\"] <= 1.5].index, \"independent_unreliable\"] = 1\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"transparency\"] > 1.5].index, \"independent_unreliable\"] = 0\n",
    "# original defintion: sources with accuracy = 1 or 2 are unreliable\n",
    "# since accuracy can have non-integer values after averaging, we decide to\n",
    "# label tweets with an average domain accuracy value of links of <= 2.5 as\n",
    "# \"unreliable\", since that means that the majority of domains linked to in \n",
    "# the tweet are unreliable. If one domain with accuracy 2 and one domain \n",
    "# with accuracy 3 are linked, the tweet is unreliable.\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"accuracy\"] <= 2.5].index, \"independent_unreliable\"] = 1\n",
    "average_scores.loc[average_scores[\\\n",
    "            average_scores[\"accuracy\"] > 2.5].index, \"independent_unreliable\"] = 0\n",
    "\n",
    "tweets = pd.merge(tweets, average_scores, how=\"left\", left_on=\"id\", right_on=\"id\")\n",
    "del average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcce382-f6bf-4ad7-9b57-08ef20082a65",
   "metadata": {},
   "source": [
    "# Create a user data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc2de824-8f53-4876-abf6-01056ffdc0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = tweets[[\"author_id\", \"handle\", \"name\", \"party\", \"id\"]]\\\n",
    "    .groupby([\"author_id\", \"handle\", \"name\", \"party\"])\\\n",
    "    .agg(\"count\")\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"id\":\"N_tweets\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295d1f2-3815-4634-a192-dfa5166f6aa5",
   "metadata": {},
   "source": [
    "## Add account stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd97affd-963c-4ed5-9fcb-74a04207b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/users\"\n",
    "fname = \"US_politician_twitter_accounts_clean.csv\"\n",
    "cols = [\"followers_count\", \"following_count\", \"tweet_count\", \"created_at\", \n",
    "        \"author_id\"]\n",
    "account_stats = pd.read_csv(\n",
    "    join(src, fname),\n",
    "    parse_dates=[\"created_at\"],\n",
    "    usecols=cols,\n",
    "    dtype={\"author_id\":str}\n",
    ")\n",
    "\n",
    "users = pd.merge(users, account_stats, how=\"left\", left_on=\"author_id\", right_on=\"author_id\")\n",
    "del account_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261401b6-eb61-4495-9bdb-a12570397fa0",
   "metadata": {},
   "source": [
    "## Add Congress information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e69ec38a-a3d1-4452-b740-ab537fbe7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/users/clean\"\n",
    "fname = \"congress-member-twitter-handles_114-117.csv\"\n",
    "congress_twitter_handles = pd.read_csv(join(src, fname))\n",
    "congress_twitter_handles = congress_twitter_handles\\\n",
    "    .sort_values(by=\"congress\", ascending=False)\\\n",
    "    .drop_duplicates(subset=\"handle\")\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "users = pd.merge(users, congress_twitter_handles, how=\"left\", left_on=\"handle\",\n",
    "                 right_on=\"handle\")\n",
    "del congress_twitter_handles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11974ba2-c6c1-42fa-9d99-bc1f1b949fd6",
   "metadata": {},
   "source": [
    "## Add share of untrustworthy domains (NewsGuard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a056d98f-6208-40d2-bb48-68e7861ac7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>NG_unreliable_sum</th>\n",
       "      <th>NG_unreliable_count</th>\n",
       "      <th>NG_unreliable_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009269193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011053278304592000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id  NG_unreliable_sum  NG_unreliable_count  \\\n",
       "0           1009269193                0.0                  221   \n",
       "1  1011053278304592000                0.0                    0   \n",
       "\n",
       "   NG_unreliable_share  \n",
       "0                  0.0  \n",
       "1                  NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"author_id\", \"NG_unreliable\"]\n",
    "unreliable_user_count = tweets[tweets[\"retweeted\"] == False][cols]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .agg([\"sum\", \"count\"])\n",
    "\n",
    "unreliable_user_count[\"NG_unreliable_share\"] = \\\n",
    "    unreliable_user_count[\"NG_unreliable\"][\"sum\"] / \\\n",
    "    unreliable_user_count[\"NG_unreliable\"][\"count\"]\n",
    "    \n",
    "# flatten the hierarchical indices\n",
    "unreliable_user_count = unreliable_user_count.reset_index()\n",
    "unreliable_user_count.columns = ['_'.join(col).strip(\"_\") \\\n",
    "                            for col in unreliable_user_count.columns.values]\n",
    "\n",
    "unreliable_user_count.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e070f70f-4543-4858-be3e-cf2bded68125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"NG_unreliable_share\", \"author_id\"]\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    unreliable_user_count[cols],\n",
    "    how=\"left\",\n",
    "    left_on=\"author_id\",\n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1daea-e29c-4328-b1c2-05f8e18f3a0b",
   "metadata": {},
   "source": [
    "## Add average NewsGuard score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7b53b46-f10e-4ef0-93e9-e86325f82211",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_NG_scores = tweets[tweets[\"retweeted\"] == False][[\"author_id\", \"NG_score\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"NG_score\":\"NG_score_mean\"})\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    average_NG_scores, \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6307c56-adfd-4d83-b111-9bb2e8461225",
   "metadata": {},
   "source": [
    "## Add average accuracy & transparency score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d17fb525-9a04-4192-8d16-7729d7041660",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy_transparency = tweets[tweets[\"retweeted\"] == False]\\\n",
    "    [[\"author_id\", \"accuracy\", \"transparency\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\n",
    "        \"accuracy\":\"accuracy_mean\",\n",
    "        \"transparency\":\"transparency_mean\"\n",
    "    })\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    average_accuracy_transparency, \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a4007-d097-44f5-a790-14bc31711dec",
   "metadata": {},
   "source": [
    "## Add share of unstrustworthy domains (independent list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40b07a89-36ca-4677-a73b-e853a1a20029",
   "metadata": {},
   "outputs": [],
   "source": [
    "unreliable_user_count = tweets[tweets[\"retweeted\"] == False]\\\n",
    "    [[\"author_id\", \"independent_unreliable\"]]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .agg([\"sum\", \"count\"])\n",
    "\n",
    "unreliable_user_count[\"independent_unreliable_share\"] = \\\n",
    "    unreliable_user_count[\"independent_unreliable\"][\"sum\"] / \\\n",
    "    unreliable_user_count[\"independent_unreliable\"][\"count\"]\n",
    "    \n",
    "# flatten the hierarchical indices\n",
    "unreliable_user_count = unreliable_user_count.reset_index()\n",
    "unreliable_user_count.columns = ['_'.join(col).strip(\"_\") \\\n",
    "                            for col in unreliable_user_count.columns.values]\n",
    "\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    unreliable_user_count[[\"author_id\", \"independent_unreliable_share\"]],\n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "del unreliable_user_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20835b75-393f-43b7-a90d-1052d64f34e8",
   "metadata": {},
   "source": [
    "## Add average belief-speaking and truth-seeking score different embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11c755fd-f871-4c72-9143-70f9c48bb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\"avg_belief_score_glove\", \"avg_belief_score_word2vec\", \"avg_belief_score_fasttext\",\n",
    "        \"avg_truth_score_glove\", \"avg_truth_score_word2vec\", \"avg_truth_score_fasttext\"]\n",
    "cols = [\"author_id\", \"created_at\"] + scores \n",
    "        \n",
    "honesty_tweets_score = tweets[tweets[\"retweeted\"] == False][cols]\\\n",
    "    .dropna(subset=scores)\\\n",
    "    .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb06c889-9244-4d11-871d-19fdf897b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all honesty component tweets\n",
    "honesty_score_average = honesty_tweets_score\\\n",
    "    [[\"author_id\"] + scores]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\n",
    "honesty_score_average = honesty_score_average.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a512ab21-cf2c-4ed1-9c59-7fae1e05ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.merge(\n",
    "    honesty_score_average[[\"author_id\"] + scores], \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "del honesty_score_average\n",
    "del honesty_tweets_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491751b0-69f0-47f7-a95b-3380f7d4cc1c",
   "metadata": {},
   "source": [
    "## Add average belief-speaking and truth-seeking score dictionary bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0076a7f7-cc12-4a54-90a8-962398cd628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [f\"avg_truth_score_{i}\" for i in range(100)] + \\\n",
    "         [f\"avg_belief_score_{i}\" for i in range(100)]\n",
    "cols = [\"author_id\", \"created_at\"] + scores \n",
    "        \n",
    "honesty_tweets_score = tweets[tweets[\"retweeted\"] == False][cols]\\\n",
    "    .dropna(subset=scores)\\\n",
    "    .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "434f6d6d-ed0c-486e-a1a7-a378a3989e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all honesty component tweets\n",
    "honesty_score_average = honesty_tweets_score\\\n",
    "    [[\"author_id\"] + scores]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\n",
    "honesty_score_average = honesty_score_average.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "25bc2fc0-d3d8-4167-8c50-8fa4060442c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.merge(\n",
    "    honesty_score_average[[\"author_id\"] + scores], \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")\n",
    "del honesty_score_average\n",
    "del honesty_tweets_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ebb33-9474-4a43-9c1a-92a1d10c950f",
   "metadata": {},
   "source": [
    "## Add average emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d48e23f5-70d8-4dd8-ac44-f69c5d1a83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['LIWC_analytic', 'LIWC_authentic', 'LIWC_emo_pos',\n",
    "            'LIWC_emo_neg', 'LIWC_moral']\n",
    "average_emotion_scores = tweets[tweets[\"retweeted\"] == False]\\\n",
    "    [[\"author_id\"] + emotions]\\\n",
    "    .groupby(\"author_id\")\\\n",
    "    .mean()\\\n",
    "    .reset_index()\n",
    "emotion_map = {em:f\"{em}_mean\" for em in emotions}\n",
    "average_emotion_scores = average_emotion_scores.rename(columns=emotion_map)\n",
    "\n",
    "users = pd.merge(\n",
    "    users, \n",
    "    average_emotion_scores, \n",
    "    how=\"left\", \n",
    "    left_on=\"author_id\", \n",
    "    right_on=\"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d5df9-59f6-42d8-85e7-8c3702603805",
   "metadata": {},
   "source": [
    "## Add ideology scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e77d54eb-c6c5-4ca6-9980-9dec16b0b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/utilities\"\n",
    "fname = \"govtrack-stats-{}-{}-ideology.csv\"\n",
    "ideology_scores = pd.DataFrame()\n",
    "for year in range(2013, 2021):\n",
    "    for chamber in [\"house\", \"senate\"]:\n",
    "        tmp = pd.read_csv(join(src, \"ideology_scores\",\n",
    "                               fname.format(year, chamber)))\n",
    "        tmp[\"year\"] = year\n",
    "        tmp[\"name\"] = tmp[\"name\"].apply(lambda x: x.replace(\"b'\", \"\"))\n",
    "        tmp[\"name\"] = tmp[\"name\"].apply(lambda x: x.replace(\"'\", \"\").lower())\n",
    "        ideology_scores = pd.concat([ideology_scores, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4225918e-470e-4139-a980-d1c97587e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match politician Twitter account names to govtrack politician names\n",
    "\n",
    "# a single politician can have at maximum 8 entries for 8 different years\n",
    "# 2013 to 2020\n",
    "counts = ideology_scores[\"name\"].value_counts()\n",
    "unique_names = list(counts[counts <= 8].index)\n",
    "\n",
    "unique_scores = ideology_scores[ideology_scores[\"name\"].isin(unique_names)]\\\n",
    "    .sort_values(by=\"year\", ascending=False)\\\n",
    "    .drop_duplicates(subset=[\"name\"])\\\n",
    "    .set_index(\"name\")\n",
    "unique_names = list(set(unique_scores.index))\n",
    "\n",
    "def match_score(account_name):\n",
    "    '''Matches govtrack politician names to Twitter account names.'''\n",
    "    if account_name == account_name:\n",
    "        account_name = set(account_name.lower().split(\" \"))\n",
    "        for name in unique_names:\n",
    "            # hard matching: if the govtrack name string is completely included\n",
    "            # in the Twitter account name string, record a match\n",
    "            if name in account_name:\n",
    "                return unique_scores.loc[name][\"id\"]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "users[\"ideology_score_id\"] = users[\"name\"].apply(match_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28e6f597-1240-4040-a814-8fab957ba0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hand-matched missing scores\n",
    "src = \"../../data/utilities\"\n",
    "fname = \"missing_govtrack_ideology_scores.csv\"\n",
    "missing_scores = pd.read_csv(join(src, fname))\n",
    "missing_scores = {row[\"handle\"]:row[\"ideology_score_id\"] \\\n",
    "                  for i, row in missing_scores.iterrows()}\n",
    "\n",
    "# index on the handle since this seems to be the most consistent index between\n",
    "# the two datasets\n",
    "users = users.set_index(\"handle\")\n",
    "for handle, score_id in missing_scores.items():\n",
    "    if handle in users.index:\n",
    "        users.loc[handle, \"ideology_score_id\"] = score_id\n",
    "users = users.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "970b5966-4348-4e4a-b270-9f7b87177fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for many accounts, there is more than one ideology score since they were \n",
    "# active over many years. We calculate the mean, std and count of the ideology\n",
    "# score for each user and add this information to the user_df\n",
    "ideology_scores_agg = ideology_scores[[\"id\", \"ideology\"]]\\\n",
    "    .groupby(\"id\")\\\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "ideology_scores_agg = ideology_scores_agg.reset_index()\n",
    "ideology_scores_agg.columns = ['_'.join(col).strip(\"_\") \\\n",
    "                            for col in ideology_scores_agg.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74895b07-eee3-4235-8818-e5c9e2f799e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.merge(ideology_scores_agg, how=\"left\", \n",
    "                      left_on=\"ideology_score_id\", right_on=\"id\")\n",
    "del ideology_scores\n",
    "del ideology_scores_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e52b7e7-4487-4e38-a701-e572c43930dc",
   "metadata": {},
   "source": [
    "## Add Politifact scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc203c1d-6d46-413d-a1b5-2fb3a1e88b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"../../data/utilities\"\n",
    "fname = \"misinfo_score_politifact.csv\"\n",
    "pf_scores = pd.read_csv(join(src, fname), \n",
    "        usecols=[\"pf_score\", \"elite_account\"])\\\n",
    "    .rename(columns={\"elite_account\":\"handle\"})\n",
    "\n",
    "users = pd.merge(users, pf_scores, how=\"left\", left_on=\"handle\", right_on=\"handle\")\n",
    "del pf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c0265-fecb-4048-bd50-802e4eeb3177",
   "metadata": {},
   "source": [
    "# Data exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f0fcc5e-1982-4323-801c-6614c8250d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38c29338-6b28-41e7-b93c-c2ae005d9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL data frame\n",
    "fname = \"US_politician_URLs_2010-11-06_to_2022-03-16_rb.csv.gzip\"\n",
    "urls = urls[urls[\"has_url\"] == True]\n",
    "urls = urls.drop(columns=[\"url\", \"domain\", \"status_code\", \"handle\", \"name\", \"has_url\"])\n",
    "urls.to_csv(join(dst, \"urls\", fname), index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d12e8d4-6651-4dc0-988a-fca8d50be901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user data frame\n",
    "fname = \"US_politician_accounts_2010-11-06_to_2022-03-16_rb.csv\"\n",
    "users = users.drop(columns=[\"ideology_score_id\", \"id\"])\n",
    "users.to_csv(join(dst, \"users\", fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2e6b858-14f8-40d0-bdc4-7ad842836fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet data frame\n",
    "fname = \"US_politician_tweets_2010-11-06_to_2022-03-16_rb.csv.gzip\"\n",
    "tweets = tweets.drop(columns=[\"handle\", \"name\"])\n",
    "tweets.to_csv(join(dst, \"tweets\", fname), index=False, compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
